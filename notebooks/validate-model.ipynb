{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Validate Model\n",
    "\n",
    "Scores the trained model on the holdout test set and prints a classification report with ROC AUC.\n",
    "\n",
    "**Pipeline context:** This notebook is the missing \"Validate\" step. It gets added to the pipeline visually using the **Elyra pipeline editor**, inserted between Train Model and Upload Model.\n",
    "\n",
    "**Quality gate:** If AUC falls below 0.7, the model should be retrained with different hyperparameters or more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and test data from the previous pipeline step\n",
    "MODEL_PATH = \"model.pkl\"\n",
    "TEST_DATA_PATH = \"test_data.npz\"\n",
    "\n",
    "print(\"Loading trained model...\")\n",
    "with open(MODEL_PATH, \"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "\n",
    "print(\"Loading test data...\")\n",
    "test_data = np.load(TEST_DATA_PATH)\n",
    "X_test, y_test = test_data[\"X_test\"], test_data[\"y_test\"]\n",
    "\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions and compute metrics\n",
    "y_pred = clf.predict(X_test)\n",
    "y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Legitimate\", \"Fraud\"]))\n",
    "print(f\"ROC AUC Score: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality gate\n",
    "if auc < 0.7:\n",
    "    print(\"WARNING: AUC below 0.7 threshold -- model may need retraining\")\n",
    "elif auc < 0.9:\n",
    "    print(\"Model quality: ACCEPTABLE (AUC 0.7-0.9)\")\n",
    "else:\n",
    "    print(\"Model quality: GOOD (AUC > 0.9)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
