#!/bin/bash

######################################################################
# RHOAI Demo Script
# Uses demo-magic for stepped command execution with commentary.
# Press ENTER to advance each step. Ctrl+C to exit.
#
# Prerequisites (run setup.sh first):
#   - oc CLI logged into target cluster
#   - NFD Operator installed
#   - NVIDIA GPU Operator installed with ClusterPolicy
#   - GPU machineset provisioned (A10G x2)
#   - MinIO deployed (S3 storage)
#   - MySQL deployed (Model Registry backend)
######################################################################

DEMO_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Preflight: check required tools
MISSING=""
for tool in oc bat helm; do
  if ! command -v "$tool" &>/dev/null; then
    MISSING="$MISSING $tool"
  fi
done
if ! oc whoami &>/dev/null; then
  MISSING="$MISSING oc(not-logged-in)"
fi
if [ -n "$MISSING" ]; then
  echo "ERROR: Missing required tools:$MISSING"
  echo ""
  echo "  oc   â†’ brew install openshift-cli (or download from OpenShift console)"
  echo "  bat  â†’ brew install bat"
  echo "  helm â†’ brew install helm"
  echo "  oc login â†’ oc login <cluster-url>"
  exit 1
fi

# Source demo-magic
. "${DEMO_DIR}/demo-magic.sh" -n

# Helper: verify a condition before continuing, retry on failure
# Usage: verify_step "description" "command that returns 0 on success"
verify_step() {
  local desc="$1"
  local cmd="$2"
  while true; do
    if eval "$cmd" &>/dev/null; then
      echo -e "  ${GREEN}âœ… ${desc}${COLOR_RESET}"
      return 0
    else
      echo -e "  ${RED}âŒ ${desc} -- not ready${COLOR_RESET}"
      echo ""
      read -p "  Press ENTER to retry, or 's' to skip: " choice
      if [ "$choice" = "s" ]; then
        echo -e "  ${CYAN}â­ï¸  Skipped${COLOR_RESET}"
        return 1
      fi
    fi
  done
}

# Helper: compare live resource against manifest, show diff if mismatched
# Usage: verify_manifest "description" "manifest-file"
verify_manifest() {
  local desc="$1"
  local manifest="$2"
  while true; do
    local diff_output
    diff_output=$(oc diff -f "${DEMO_DIR}/${manifest}" 2>&1)
    local rc=$?
    if [ $rc -eq 0 ]; then
      echo -e "  ${GREEN}âœ… ${desc} -- matches manifest${COLOR_RESET}"
      return 0
    elif [ $rc -eq 1 ]; then
      echo -e "  ${CYAN}âš ï¸  ${desc} -- differs from manifest:${COLOR_RESET}"
      echo ""
      echo "$diff_output"
      echo ""
      read -p "  (a)pply manifest to fix / (c)ontinue anyway / (r)etry check: " choice
      case "$choice" in
        a) oc apply -f "${DEMO_DIR}/${manifest}" &>/dev/null
           echo -e "  ${GREEN}  Applied.${COLOR_RESET}"
           continue ;;
        c) return 0 ;;
        *) continue ;;
      esac
    else
      echo -e "  ${RED}âŒ ${desc} -- not found or error${COLOR_RESET}"
      echo ""
      read -p "  Press ENTER to retry, or 's' to skip: " choice
      if [ "$choice" = "s" ]; then
        echo -e "  ${CYAN}â­ï¸  Skipped${COLOR_RESET}"
        return 1
      fi
    fi
  done
}

# Helper: section header with optional skip
# Returns 1 if skipped (use: begin_section ... || return 0)
begin_section() {
  local num="$1" icon="$2" title="$3"
  echo ""
  echo -e "# ${icon} ${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${COLOR_RESET}"
  echo -e "# ${GREEN}SECTION ${num}: ${title}${COLOR_RESET}"
  echo -e "# ${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${COLOR_RESET}"
  read -p "  Skip this section? (y/N): " SKIP_SECTION
  if [ "$SKIP_SECTION" = "y" ]; then
    echo -e "  ${CYAN}â­ï¸  Skipped Section ${num}${COLOR_RESET}"
    return 1
  fi
  return 0
}

# Helper: ensure a variable is set, try to resolve it if not
# Usage: ensure_var RHOAI_URL "oc get gateway ..."
ensure_var() {
  local varname="$1"
  local cmd="$2"
  if [ -z "${!varname:-}" ]; then
    local val
    val=$(eval "$cmd" 2>/dev/null) || true
    if [ -n "$val" ]; then
      eval "$varname=\"$val\""
      echo -e "  ${GREEN}âœ… ${varname} resolved${COLOR_RESET}"
    else
      echo -e "  ${RED}âš ï¸  Could not resolve ${varname} -- was a previous section skipped?${COLOR_RESET}"
    fi
  fi
}

# Configure
DEMO_PROMPT="${GREEN}âœ ${CYAN}\W ${COLOR_RESET}"
TYPE_SPEED=20

# Detect browser-open command (macOS vs Linux)
if command -v open &>/dev/null; then
  BROWSER_OPEN="open"
elif command -v xdg-open &>/dev/null; then
  BROWSER_OPEN="xdg-open"
else
  BROWSER_OPEN="echo"   # fallback: just print the URL
fi

clear

echo ""
echo -e "${GREEN}  ___                 ___ _    _  __ _       _   ___ ${COLOR_RESET}"
echo -e "${GREEN} / _ \ _ __  ___ _ _ / __| |_ (_)/ _| |_    /_\ |_ _|${COLOR_RESET}"
echo -e "${GREEN}| (_) | '_ \/ -_) ' \\\\__ \ ' \| |_|  _|     / _ \ | | ${COLOR_RESET}"
echo -e "${GREEN} \___/| .__/\___|_||_|___/_||_|_|_|  \__| /_/ \_\___|${COLOR_RESET}"
echo -e "${GREEN}      |_|${COLOR_RESET}         ${CYAN}Get Started with OpenShift AI${COLOR_RESET}"
echo ""
echo -e "  ${CYAN}FSI Bootcamp Demo  â€¢  GPU-Accelerated ML on OpenShift${COLOR_RESET}"
echo ""

wait

######################################################################
# Section functions
######################################################################

section_1() {
begin_section 1 "ğŸ”" "Check Current State" || return 0
echo "#"
echo "# ğŸ“‹ What's already on this cluster (from setup):"
echo "#   â€¢ NFD Operator -- discovers hardware features"
echo "#   â€¢ NVIDIA GPU Operator -- manages the GPU stack"

wait

pe "oc get csv -A | grep -E 'nvidia|nfd|rhods'"

echo ""
echo "# ğŸ–¥ï¸  GPU nodes online?"

wait

pe "oc get nodes -l nvidia.com/gpu.present=true"

pe "oc get nodes -l nvidia.com/gpu.present=true -o custom-columns='NODE:.metadata.name,TAINT:.spec.taints[*].key,EFFECT:.spec.taints[*].effect'"

echo ""
echo "# ğŸš« These GPU nodes are tainted: nvidia.com/gpu=NoSchedule"
echo "#   â€¢ Set by the MachineSet -- nodes come up pre-tainted"
echo "#   â€¢ GPU Operator pods tolerate it (they have to run there)"
echo "#   â€¢ Everything else is blocked â†’ protects expensive GPU nodes"
echo "#   â€¢ We'll need a HardwareProfile later to let ML workloads in"

wait
}

section_2() {
begin_section 2 "ğŸ”" "Node Feature Discovery (NFD)" || return 0
echo "#"
echo "# ğŸ‘ï¸  NFD = the eyes of the cluster"
echo "#   â€¢ DaemonSet on every node -- scans for hardware"
echo "#   â€¢ GPUs, FPGAs, SR-IOV -- auto-labeled on the node"
echo "#   â€¢ GPU Operator reads these labels to deploy drivers"

wait

pe "oc get nodefeaturediscovery -n openshift-nfd"

echo ""
echo "# ğŸ·ï¸  What did NFD find on our GPU nodes?"
echo "#   NFD labels use prefix: feature.node.kubernetes.io/"
echo "#   Key ones:"
echo "#     â€¢ pci-10de.present=true  â†’ 10de = NVIDIA's PCI vendor ID"
echo "#     â€¢ kernel.version         â†’ running kernel"
echo "#     â€¢ system-os_release.ID   â†’ RHCOS / RHEL"

wait

pe "oc describe node \$(oc get nodes -l nvidia.com/gpu.present=true -o jsonpath='{.items[0].metadata.name}') | grep -E 'pci-10de|kernel-version.full|os_release.ID|cpu-model.vendor'"

wait
}

section_3() {
begin_section 3 "ğŸ®" "NVIDIA GPU Operator" || return 0
echo "#"
echo "# ğŸ”§ One operator, entire GPU stack:"
echo "#   â€¢ Drivers, device plugins, container toolkit, monitoring"
echo "#   â€¢ All driven by a single CR: ClusterPolicy"

wait

pe "oc get clusterpolicy"

echo ""
echo "# ğŸ“‹ What does the ClusterPolicy configure?"

wait

pe "bat --style=grid,numbers manifests/gpu-cluster-policy.yaml"

echo ""
echo ""
echo "# ğŸ·ï¸  GPU Feature Discovery (GFD) adds nvidia.com/gpu.* labels"
echo "#   â€¢ Product name, VRAM, CUDA version, driver version"
echo "#   â€¢ Different from NFD -- GFD queries the GPU directly"

wait

pe "oc get nodes -l nvidia.com/gpu.present=true -o custom-columns='NODE:.metadata.name,GPU:.metadata.labels.nvidia\.com/gpu\.product,VRAM_MB:.metadata.labels.nvidia\.com/gpu\.memory,GPUs:.status.allocatable.nvidia\.com/gpu'"

echo ""
echo "# ğŸš€ Moment of truth -- nvidia-smi"
echo "#   â€¢ NVIDIA System Management Interface -- CLI to query the GPU"
echo "#   â€¢ We're running it FROM INSIDE a driver pod (not the host)"
echo "#   â€¢ If it returns output, the full stack is working:"
echo "#     drivers compiled â†’ device plugin registered â†’ toolkit configured"
echo "#"
echo "# ğŸ“– How to read the output:"
echo "#   â€¢ GPU name + VRAM (A10G, 23028MiB â‰ˆ 22.5GiB -- marketed as 24GB)"
echo "#   â€¢ Driver 570.x + CUDA 12.8"
echo "#   â€¢ Pwr: 24W/300W â†’ idle draw / max cap (300W under full load)"
echo "#   â€¢ P8 = performance state (P0=max, P12=min) -- P8 means idle"
echo "#   â€¢ Temp 28C â†’ cool, expect 60-80C under load"
echo "#   â€¢ GPU-Util 0%, no processes â†’ nothing scheduled yet"

wait

pe "oc exec -n nvidia-gpu-operator \$(oc get pods -n nvidia-gpu-operator --no-headers | grep driver | awk '{print \$1}' | head -n 1) -c nvidia-driver-ctr -- nvidia-smi"

wait
}

section_4() {
begin_section 4 "ğŸ“¦" "Install Red Hat OpenShift AI" || return 0
echo "#"
echo "# ğŸ§  RHOAI = the ML platform layer on top of OpenShift"
echo "#   â€¢ Workbenches, model serving, pipelines, model registry"
echo "#   â€¢ Model Catalog with pre-validated foundation models"
echo "#   â€¢ LlamaStack for GenAI inference and chat"
echo "#   â€¢ Install the operator from OperatorHub in the console"

wait

pe "OCP_CONSOLE=\$(oc whoami --show-console) && echo \$OCP_CONSOLE"

pe "$BROWSER_OPEN \$OCP_CONSOLE"

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Install RHOAI in browser${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# ğŸŒ OpenShift Console â†’ Operators â†’ OperatorHub"
echo "#   â†’ Search: 'OpenShift AI'"
echo "#   â†’ Click 'Red Hat OpenShift AI'"
echo "#   â†’ Click 'Install'"
echo "#   â†’ Channel: fast | Update approval: Automatic"
echo "#   â†’ Accept all other defaults â†’ Click 'Install'"
echo "#   â†’ â³ Wait for CSV status: 'Succeeded'"
echo "#"
echo -e "# ${RED}   DO NOT press ENTER until the operator shows 'Succeeded'${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo "# ğŸ”„ Verify the operator installed:"

wait

pe "oc get csv -n redhat-ods-operator | grep rhods"

verify_step "RHOAI operator CSV is Succeeded" "oc get csv -n redhat-ods-operator 2>/dev/null | grep rhods | grep -q Succeeded"

echo ""
echo "# ğŸ§© The operator is installed, but it doesn't DO anything yet."
echo "#   We need a DataScienceCluster (DSC) -- the CR that tells"
echo "#   the operator which components to activate."
echo "#"
echo "# ğŸ“‹ DSC components we need:"
echo "#   â€¢ Dashboard, Workbenches, ModelRegistry â†’ Managed (defaults)"
echo "#   â€¢ KServe â†’ Managed (model serving)"
echo "#   â€¢ DataSciencePipelines â†’ Managed (ML pipelines)"
echo "#   â€¢ LlamaStack â†’ Managed (NOT default -- must enable)"
echo "#   â€¢ ModelMeshServing â†’ Removed (deprecated, KServe replaces it)"

wait

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Create DataScienceCluster${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# ğŸŒ OpenShift Console â†’ Installed Operators â†’ Red Hat OpenShift AI"
echo "#   â†’ 'DataScienceCluster' tab â†’ Click 'Create DataScienceCluster'"
echo "#   â†’ Switch to YAML view"
echo "#"
echo "# ğŸ“ Find the llamastackoperator section and change it:"
echo "#     llamastackoperator:"
echo "#       managementState: Managed     â† change from Removed to Managed"
echo "#"
echo "# ğŸ’¡ All other defaults are fine (Dashboard, KServe, Workbenches,"
echo "#   ModelRegistry, Pipelines are already Managed by default)"
echo "#"
echo "#   â†’ Click 'Create'"
echo "#   â†’ â³ Wait for status: Phase = Ready (may take 2-3 minutes)"
echo "#"
echo -e "# ${RED}   DO NOT press ENTER until the DSC shows Phase: Ready${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo "# ğŸ”„ Checking RHOAI readiness..."
verify_step "DataScienceCluster exists" "oc get datasciencecluster default-dsc 2>/dev/null"
verify_step "DataScienceCluster phase is Ready" "oc get datasciencecluster default-dsc -o jsonpath='{.status.phase}' 2>/dev/null | grep -q Ready"
verify_step "Dashboard is ready" "oc get datasciencecluster default-dsc -o jsonpath='{.status.conditions[?(@.type==\"DashboardReady\")].status}' 2>/dev/null | grep -q True"
verify_step "KServe is ready" "oc get datasciencecluster default-dsc -o jsonpath='{.status.conditions[?(@.type==\"KserveReady\")].status}' 2>/dev/null | grep -q True"
verify_step "Workbenches ready" "oc get datasciencecluster default-dsc -o jsonpath='{.status.conditions[?(@.type==\"WorkbenchesReady\")].status}' 2>/dev/null | grep -q True"
verify_step "RHOAI Dashboard gateway exists" "oc get gateway data-science-gateway -n openshift-ingress 2>/dev/null"

pe "RHOAI_URL=https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}') && echo \$RHOAI_URL"

echo ""
echo "# ğŸ“‹ What's managed vs removed:"

wait

pe "oc get datasciencecluster -o yaml | grep -A1 managementState"

echo ""
echo "# âœ… RHOAI 3.0 is ready -- all components healthy, LlamaStack enabled"

wait
}

section_5() {
begin_section 5 "ğŸ›¡ï¸ " "Hardware Profile with GPU Toleration" || return 0
# Depends on: RHOAI installed, RHOAI_URL set (Section 4)
verify_step "RHOAI operator is installed" "oc get csv -A 2>/dev/null | grep rhods | grep -q Succeeded"
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
echo "#"
echo "# ğŸ”‘ Remember the GPU taint from Section 1?"
echo "#   â€¢ HardwareProfile is how RHOAI workloads get past it"
echo "#   â€¢ Defines: CPU + Memory + GPU requests"
echo "#   â€¢ Includes toleration so pods CAN schedule on tainted GPU nodes"

wait

echo ""
echo "# ğŸ“‹ Here's what the HardwareProfile looks like:"

wait

pe "bat --style=grid,numbers manifests/hardware-profile.yaml"

echo ""
echo "# ğŸ”§ Two ways to create this profile:"
echo "#"
echo "#   Option A: Apply the manifest (oc apply)"
echo "#   Option B: Create it manually in the RHOAI Dashboard"
echo "#     â†’ Settings â†’ Hardware profiles â†’ 'Create hardware profile'"
echo "#     â†’ Name: nvidia-gpu"
echo "#     â†’ Add identifiers: CPU (2 default), Memory (8Gi), nvidia.com/gpu (1)"
echo "#     â†’ Add toleration: key=nvidia.com/gpu, effect=NoSchedule, operator=Exists"
echo ""
read -p "  Apply manifest now? (y/n): " HP_CHOICE
if [ "$HP_CHOICE" = "y" ]; then
  pe "oc apply -f manifests/hardware-profile.yaml"
else
  echo ""
  echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
  echo -e "# ${RED}   ACTION REQUIRED -- Create HardwareProfile in RHOAI Dashboard${COLOR_RESET}"
  echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
  echo "#"
  echo "# ğŸŒ RHOAI Dashboard â†’ Settings â†’ Hardware profiles"
  echo "#   â†’ Click 'Create hardware profile'"
  echo "#   â†’ Name: nvidia-gpu"
  echo "#   â†’ Add identifiers:"
  echo "#     â€¢ CPU:            default=2, min=1, max=8"
  echo "#     â€¢ Memory:         default=8Gi, min=2Gi, max=32Gi"
  echo "#     â€¢ nvidia.com/gpu: default=1, min=1, max=2 (type: Accelerator)"
  echo "#   â†’ Node scheduling â†’ Add toleration:"
  echo "#     â€¢ Key: nvidia.com/gpu"
  echo "#     â€¢ Effect: NoSchedule"
  echo "#     â€¢ Operator: Exists"
  echo "#   â†’ Click 'Create'"
  echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
  wait
fi

echo ""
verify_step "HardwareProfile 'nvidia-gpu' exists" "oc get hardwareprofile nvidia-gpu -n redhat-ods-applications 2>/dev/null"
verify_manifest "HardwareProfile config" "manifests/hardware-profile.yaml"

wait

pe "$BROWSER_OPEN \$RHOAI_URL"

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Verify HardwareProfile in browser${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# ğŸŒ RHOAI Dashboard â†’ Settings â†’ Hardware profiles"
echo "#   â†’ 'NVIDIA GPU (A10G)' should appear"
echo "#   â†’ Click it to verify:"
echo "#     â€¢ CPU: 2 (1-8)"
echo "#     â€¢ Memory: 8Gi (2Gi-32Gi)"
echo "#     â€¢ nvidia.com/gpu: 1 (1-2)"
echo "#     â€¢ Toleration: nvidia.com/gpu NoSchedule"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait
}

section_6() {
begin_section 6 "ğŸŒŸ" "Model Catalog â€” Deploy Granite LLM" || return 0
# Depends on: RHOAI installed (Section 4), HardwareProfile (Section 5)
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
verify_step "HardwareProfile exists" "oc get hardwareprofile nvidia-gpu -n redhat-ods-applications 2>/dev/null"
echo "#"
echo "# ğŸŒŸ RHOAI includes a Model Catalog of pre-validated models"
echo "#   â€¢ Red Hat AI Validated: tested, supported, enterprise-ready"
echo "#   â€¢ Delivered as OCI ModelCar container images"
echo "#   â€¢ One-click deploy from the Dashboard"
echo "#"
echo "# ğŸ“¦ ModelCar = model weights packaged as a container image"
echo "#   â€¢ Pulled by the container runtime just like app images"
echo "#   â€¢ Version-tagged, registry-hosted, no S3 needed"
echo "#   â€¢ Same pull/cache/distribute pipeline as any container"
echo "#"
echo "# ğŸ¯ We'll deploy Granite 3.1 8B Instruct (W4A16 quantized)"
echo "#   â€¢ IBM's enterprise LLM -- instruction-tuned for chat"
echo "#   â€¢ W4A16 = 4-bit weights, 16-bit activations"
echo "#   â€¢ Fits easily on our A10G (24GB VRAM)"
echo "#   â€¢ Served via vLLM -- high-performance LLM inference engine"

wait

pe "$BROWSER_OPEN \$RHOAI_URL"

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Deploy Granite from Model Catalog${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# ğŸŒ RHOAI Dashboard â†’ Model Catalog (left sidebar)"
echo "#   â†’ Browse the catalog -- show the audience what's available"
echo "#   â†’ Find: Granite 3.1 8B Instruct (quantized W4A16)"
echo "#   â†’ Click the model card â†’ review description, license"
echo "#   â†’ Click 'Deploy'"
echo "#"
echo "# ğŸ“ Deployment settings:"
echo "#   â†’ Model name:       granite-llm"
echo "#   â†’ Project:           Create new â†’ granite-demo"
echo "#   â†’ Serving runtime:   vLLM ServingRuntime for KServe"
echo "#   â†’ Hardware profile:  nvidia-gpu (NVIDIA GPU A10G)"
echo "#   â†’ Model location:    should be pre-filled from catalog"
echo "#     oci://registry.redhat.io/rhelai1/modelcar-granite-3-1-8b-instruct-quantized-w4a16:1.5"
echo "#   â†’ Advanced settings:"
echo "#     â€¢ External route: UNCHECKED (internal only)"
echo "#     â€¢ Token auth: UNCHECKED"
echo "#   â†’ Click 'Deploy'"
echo "#"
echo "# â³ The model image will start pulling. This takes a few minutes"
echo "#   if not pre-warmed. We'll fill the time in the next section!"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo "# ğŸ”„ Verify the deployment started:"

wait

pe "oc get inferenceservice -n granite-demo"

echo ""
echo "# â³ Model is pulling/loading. Let's talk about serving runtimes"
echo "#   and backing services while we wait..."

wait
}

section_7() {
begin_section 7 "ğŸ”§" "Serving Runtimes & Backing Services" || return 0
# Depends on: RHOAI installed (Section 4)
verify_step "RHOAI operator is installed" "oc get csv -A 2>/dev/null | grep rhods | grep -q Succeeded"
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
echo "#"
echo "# ğŸ–¥ï¸  Serving Runtimes = how models run on GPUs"
echo "#   â€¢ RHOAI supports multiple runtimes for different use cases"
echo "#   â€¢ vLLM: high-performance LLM inference (what Granite uses)"
echo "#   â€¢ Triton: multi-framework ML inference (TF, ONNX, PyTorch)"
echo "#   â€¢ Each runtime is an OpenShift Template in redhat-ods-applications"
echo "#"
echo "# ğŸ“¦ RHOAI 3.0 stores runtimes as OpenShift Templates"
echo "#   â€¢ Dashboard discovers them in redhat-ods-applications"
echo "#   â€¢ Template wraps a bare ServingRuntime + metadata:"
echo "#     - API protocol (REST vs gRPC)"
echo "#     - Model type (predictive vs generative AI)"

wait

echo ""
echo "# ğŸ”§ vLLM is already available (built into RHOAI 3.0)"
echo "#   We used it to deploy Granite in the previous section."
echo "#"
echo "# ğŸ“‹ Now let's add Triton for custom ML models (TensorFlow, etc.)"
echo "#   We'll use this later when we deploy our own trained model."

wait

echo ""
echo "# ğŸ“‹ Here's the Triton ServingRuntime definition:"

wait

pe "bat --style=grid,numbers manifests/serving-runtime.yaml"

echo ""
echo "# ğŸ”§ Two ways to create this runtime:"
echo "#"
echo "#   Option A: Apply the Template manifest (oc apply)"
echo "#     â†’ Applies the pre-wrapped Template directly"
echo "#"
echo "#   Option B: Paste bare YAML in the RHOAI Dashboard"
echo "#     â†’ Dashboard asks for protocol + model type, wraps it for you"
echo ""
read -p "  Apply template manifest now? (y/n): " SR_CHOICE
if [ "$SR_CHOICE" = "y" ]; then
  pe "oc apply -f manifests/serving-runtime-template.yaml"
else
  echo ""
  echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
  echo -e "# ${RED}   ACTION REQUIRED -- Create ServingRuntime in RHOAI Dashboard${COLOR_RESET}"
  echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
  echo "#"
  echo "# ğŸ“ YAML to paste: manifests/serving-runtime.yaml"
  echo "#    (scroll up or open in another terminal)"
  echo "#"
  echo "# ğŸŒ RHOAI Dashboard â†’ Settings â†’ Serving runtimes"
  echo "#   â†’ Click 'Add serving runtime'"
  echo "#   â†’ API protocol: REST"
  echo "#     (Triton config uses HTTP only -- --allow-grpc=false)"
  echo "#   â†’ Model type: Predictive model"
  echo "#     (traditional ML: TensorFlow/Keras/ONNX, not LLM inference)"
  echo "#   â†’ Select 'Start from scratch'"
  echo "#   â†’ Paste the full YAML from manifests/serving-runtime.yaml"
  echo "#   â†’ Click 'Create'"
  echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
  wait
fi

echo ""
verify_step "ServingRuntime template exists" "oc get template triton-kserve-gpu-template -n redhat-ods-applications 2>/dev/null"

echo ""
echo "# âœ… Two serving runtimes available:"
echo "#   â€¢ vLLM â†’ LLMs (Granite, Llama, Mistral)"
echo "#   â€¢ Triton â†’ custom ML (TensorFlow, ONNX, PyTorch)"

wait

echo ""
echo "# ğŸ§± Now let's check the backing services (deployed during setup):"
echo "#"
echo "#   ğŸ“¦ MinIO â†’ S3-compatible object storage"
echo "#     â€¢ Model files, pipeline artifacts"
echo "#     â€¢ Production = AWS S3 / Ceph / ODF"
echo "#"
echo "#   ğŸ—„ï¸  MySQL â†’ Model Registry metadata"
echo "#     â€¢ Name, version, artifact paths"
echo "#     â€¢ NOT the models -- just the catalog"

wait

echo ""
echo "# ğŸ”„ Verify they're running:"

wait

pe "oc get pods -l app=minio"

pe "oc get pods -n rhoai-model-registry"

echo ""
verify_step "MinIO pod is Running" "oc get pods -l app=minio -o jsonpath='{.items[0].status.phase}' 2>/dev/null | grep -q Running"
verify_step "Model Registry DB pod is Running" "oc get pods -n rhoai-model-registry -o jsonpath='{.items[0].status.phase}' 2>/dev/null | grep -q Running"

echo ""
echo "# ğŸª£ Time to create our model storage bucket in MinIO!"
echo "#   â†’ This is where our custom trained models will land"

wait

verify_step "MinIO UI route exists" "oc get route minio-ui 2>/dev/null"

pe "MINIO_URL=\$(oc get route minio-ui -o jsonpath='https://{.spec.host}') && echo \$MINIO_URL"

pe "$BROWSER_OPEN \$MINIO_URL"

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Create 'models' bucket in MinIO${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# ğŸŒ MinIO Console:"
echo "#   â†’ Login:  Username: minio  |  Password: minio123"
echo "#   â†’ Sidebar â†’ 'Object Browser'"
echo "#   â†’ Click 'Create a Bucket'"
echo "#   â†’ Bucket name: models"
echo "#   â†’ Click 'Create Bucket'"
echo "#   â†’ Leave it empty -- notebook will upload here later"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo "# ğŸ”„ Let's check on the Granite deployment while we're here:"

wait

pe "oc get inferenceservice -n granite-demo"

echo ""
echo "# ğŸ’¡ While Granite loads, a look at where models live:"
echo "#   â€¢ LLMs from the catalog â†’ OCI ModelCar images (no S3 needed)"
echo "#   â€¢ Custom trained models â†’ S3 storage (MinIO, AWS S3, Ceph)"
echo "#   â€¢ Two paths, one platform"

wait
}

section_8() {
begin_section 8 "ğŸ’¬" "LlamaStack + Chat with Granite" || return 0
# Depends on: RHOAI installed with LlamaStack (Section 4), Granite deployed (Section 6)
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
echo "#"
echo "# ğŸ’¬ LlamaStack = unified API for LLM inference"
echo "#   â€¢ Open-source project by Meta, supported by Red Hat"
echo "#   â€¢ Provides a standard API for chat, completions, embeddings"
echo "#   â€¢ The operator was enabled in the DSC back in Section 4"
echo "#   â€¢ Now we deploy an INSTANCE pointing at our Granite model"
echo "#   â€¢ Plus a Playground UI for interactive chat"

wait

echo ""
echo "# ğŸ”„ First, let's make sure Granite is ready:"

wait

pe "oc get inferenceservice -n granite-demo"

verify_step "Granite InferenceService is Ready" "oc get inferenceservice -n granite-demo -o jsonpath='{.items[0].status.conditions[?(@.type==\"Ready\")].status}' 2>/dev/null | grep -q True"

echo ""
echo "# ğŸ¯ Granite is serving! Let's set up the chat playground."

wait

# Get the Granite internal endpoint
GRANITE_ISVC=$(oc get inferenceservice -n granite-demo -o jsonpath='{.items[0].metadata.name}' 2>/dev/null) || true
GRANITE_ENDPOINT="http://${GRANITE_ISVC}-predictor.granite-demo.svc.cluster.local:8080/v1"

# Get the model ID that vLLM is serving (needed for LlamaStack config)
GRANITE_MODEL_ID=$(oc exec -n granite-demo deploy/${GRANITE_ISVC}-predictor -c kserve-container -- curl -s http://localhost:8080/v1/models 2>/dev/null | python3 -c "import sys,json; print(json.load(sys.stdin)['data'][0]['id'])" 2>/dev/null) || GRANITE_MODEL_ID="granite"

echo ""
echo "# ğŸ”— Granite internal endpoint:"
echo "#   ${GRANITE_ENDPOINT}"
echo "#   Model ID: ${GRANITE_MODEL_ID}"

wait

echo ""
echo "# ğŸ”§ Step 1: Deploy LlamaStack operator instance"
echo "#   â€¢ Creates a LlamaStackDistribution CR"
echo "#   â€¢ The RHOAI-managed operator sees this CR and deploys:"
echo "#     - LlamaStack API server (port 8321)"
echo "#     - ConfigMap with model routing config"
echo "#   â€¢ Uses a Helm chart from the GenAIOps Helm repo"

wait

echo ""
echo "# ğŸ“‹ Installing LlamaStack operator instance via Helm..."

wait

pe "helm install llama-stack-instance genaiops/llama-stack-operator-instance \
  --namespace granite-demo \
  --set models[0].name=${GRANITE_MODEL_ID} \
  --set models[0].url=${GRANITE_ENDPOINT} \
  --set telemetry.enabled=false \
  --set otelCollector.enabled=false \
  --set rag.enabled=false \
  --set mcp.enabled=false \
  --set mcp_aihub.enabled=false \
  --set eval.enabled=false \
  --set guardrails.enabled=false"

echo ""
echo "# â³ Waiting for LlamaStack API server to start..."

wait

verify_step "LlamaStack pod is Running" "oc get pods -n granite-demo -l app.kubernetes.io/name=llama-stack -o jsonpath='{.items[0].status.phase}' 2>/dev/null | grep -q Running"

echo ""
echo "# ğŸ”§ Step 2: Deploy LlamaStack Playground UI"
echo "#   â€¢ Streamlit-based chat interface"
echo "#   â€¢ Connects to the LlamaStack API service"
echo "#   â€¢ Creates an OpenShift Route for browser access"

wait

pe "helm install llama-stack-playground genaiops/llama-stack-playground \
  --namespace granite-demo \
  --set playground.llamaStackUrl=http://llama-stack:8321 \
  --set playground.defaultModel=${GRANITE_MODEL_ID} \
  --set route.enabled=true \
  --set networkPolicy.enabled=false"

echo ""
echo "# â³ Waiting for Playground to start..."

wait

verify_step "Playground pod is Running" "oc get pods -n granite-demo -l app.kubernetes.io/name=llama-stack-playground -o jsonpath='{.items[0].status.phase}' 2>/dev/null | grep -q Running"

echo ""
echo "# ğŸŒ Opening the Playground..."

wait

pe "PLAYGROUND_URL=\$(oc get route -n granite-demo -l app.kubernetes.io/name=llama-stack-playground -o jsonpath='https://{.items[0].spec.host}') && echo \$PLAYGROUND_URL"

pe "$BROWSER_OPEN \$PLAYGROUND_URL"

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Chat with Granite!${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# ğŸŒ In the Playground:"
echo "#   â†’ Select model: ${GRANITE_MODEL_ID}"
echo "#   â†’ Try these FSI-relevant prompts:"
echo "#"
echo "#   ğŸ’¬ 'Explain the key components of Basel III capital requirements'"
echo "#   ğŸ’¬ 'What are the main risks in algorithmic trading?'"
echo "#   ğŸ’¬ 'Summarize PCI-DSS compliance requirements for payment processing'"
echo "#   ğŸ’¬ 'What is model risk management and why does it matter in banking?'"
echo "#"
echo "# ğŸ”‘ Key points for the audience:"
echo "#   â€¢ This model is running on our A10G GPU, on OpenShift"
echo "#   â€¢ Enterprise-grade: Red Hat validated, IBM-developed"
echo "#   â€¢ No data leaves the cluster -- internal inference only"
echo "#   â€¢ From catalog browse to live chat in minutes"
echo "#   â€¢ LlamaStack provides a standard API -- swap models without"
echo "#     changing your application code"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo "# âœ… Foundation model deployed from catalog and serving live!"
echo "#   Next: build and deploy your OWN custom model"

wait
}

section_9() {
begin_section 9 "ğŸ§ª" "Workbench & Train Custom Model" || return 0
# Depends on: RHOAI_URL (Section 4), MINIO_URL (Section 7),
#             HardwareProfile (Section 5), ServingRuntime (Section 7)
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
ensure_var MINIO_URL "oc get route minio-ui -o jsonpath='https://{.spec.host}'"
verify_step "HardwareProfile exists" "oc get hardwareprofile nvidia-gpu -n redhat-ods-applications 2>/dev/null"
verify_step "ServingRuntime template exists" "oc get template triton-kserve-gpu-template -n redhat-ods-applications 2>/dev/null"
echo "#"
echo "# ğŸ”€ Shift: from foundation models â†’ building your own"
echo "#   â€¢ Granite gave us GenAI out of the box"
echo "#   â€¢ But FSI needs custom models too:"
echo "#     fraud detection, credit scoring, risk pricing"
echo "#   â€¢ Same platform, same GPUs, different workflow"
echo "#"
echo "# ğŸ¯ Interactive ML workflow:"
echo "#   1ï¸âƒ£  Create Data Science Project"
echo "#   2ï¸âƒ£  Connect S3 storage"
echo "#   3ï¸âƒ£  Launch GPU workbench"
echo "#   4ï¸âƒ£  Train model + upload to MinIO"

wait

pe "$BROWSER_OPEN \$RHOAI_URL"

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Create Data Science Project${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# 1ï¸âƒ£  ğŸŒ RHOAI Dashboard:"
echo "#   â†’ 'Data Science Projects' in left sidebar"
echo "#   â†’ Click 'Create data science project'"
echo "#   â†’ Name: fsi-demo"
echo "#   â†’ Click 'Create'"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo "# âš™ï¸  While we're here, let's deploy the pipeline server"
echo "#   so it's ready when we get to Section 12."
echo "#   This takes a couple minutes to start up."

wait

pe "oc apply -f manifests/dspa.yaml"

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Create S3 Connection${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# 2ï¸âƒ£  Inside fsi-demo project â†’ 'Connections' tab"
echo "#   â†’ Click 'Create connection'"
echo "#   â†’ Connection type: S3 compatible object storage - v1"
echo "#   â†’ Connection name:  minio-models"
echo "#   â†’ Access key:       minio"
echo "#   â†’ Secret key:       minio123"
echo "#   â†’ Endpoint:         http://minio-service.default.svc.cluster.local:9000"
echo "#   â†’ Bucket:           models"
echo "#   â†’ Click 'Create'"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Create GPU Workbench${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# 3ï¸âƒ£  'Workbenches' tab â†’ 'Create workbench'"
echo "#   â†’ Name: gpu-workbench"
echo "#   â†’ Image: TensorFlow (select CUDA variant if available)"
echo "#   â†’ Hardware profile: nvidia-gpu"
echo "#   â†’ Connections â†’ check 'Attach existing connections'"
echo "#     â†’ Select: minio-models"
echo "#   â†’ Click 'Create workbench'"
echo "#   â†’ â³ Wait for status: Running"
echo "#   â†’ Click 'Open' to launch JupyterLab"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Run notebooks in JupyterLab${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# 4ï¸âƒ£  In JupyterLab terminal, clone the repo:"
echo "#   â†’ git clone https://github.com/adam-d-young/RHOAI-demo.git"
echo "#   â†’ Navigate to RHOAI-demo/notebooks/"
echo "#   â†’ Run in order:"
echo "#"
echo "#   ğŸ““ gpu-check.py        â†’ Can TensorFlow see the A10G?"
echo "#   ğŸ““ gpu-demo.py         â†’ GPU matrix multiply"
echo "#   ğŸ““ train-and-upload.py â†’ Train model, upload to MinIO"
echo "#"
echo -e "# ${RED}   DO NOT continue until train-and-upload.py completes${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

pe "$BROWSER_OPEN \$MINIO_URL"

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Verify model in MinIO${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# 5ï¸âƒ£  ğŸŒ MinIO Console:"
echo "#   â†’ Object Browser â†’ 'models' bucket"
echo "#   â†’ You should see: production/demo-model/"
echo "#     â†’ config.pbtxt"
echo "#     â†’ 1/model.savedmodel/saved_model.pb"
echo "#     â†’ 1/model.savedmodel/fingerprint.pb"
echo "#     â†’ 1/model.savedmodel/variables/"
echo "#"
echo "# âœ… Model trained on GPU, exported, and stored in S3"
echo "#   Next: register it in the Model Registry before deploying"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait
}

section_10() {
begin_section 10 "ğŸ“‹" "Model Registry" || return 0
# Depends on: RHOAI installed (Section 4), Model trained (Section 9),
#             MySQL DB deployed (setup.sh Step 8)
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
verify_step "RHOAI operator is installed" "oc get csv -A 2>/dev/null | grep rhods | grep -q Succeeded"
verify_step "Model Registry DB is running" "oc get pods -n rhoai-model-registry -o jsonpath='{.items[0].status.phase}' 2>/dev/null | grep -q Running"
echo "#"
echo "# ğŸ—‚ï¸  Model Registry = the catalog for YOUR models"
echo "#   â€¢ NOT the Model Catalog (pre-built Red Hat AI models)"
echo "#   â€¢ Tracks: name, version, description, artifact URI"
echo "#   â€¢ Add custom properties: team, regulatory, risk tier"
echo "#   â€¢ Deploy directly from the registry"
echo "#   â€¢ Full audit trail: who trained it, when, what data"
echo "#"
echo "# ğŸ“‹ In production (FSI), this is critical:"
echo "#   â€¢ Model Risk Management (SR 11-7 / SS1/23)"
echo "#   â€¢ Version control for model governance"
echo "#   â€¢ Deployment tracking across environments"

wait

echo ""
echo "# ğŸ”§ First, create the Model Registry instance"
echo "#   â€¢ The RHOAI operator installs the registry capability"
echo "#   â€¢ But we still need to create an actual registry instance"
echo "#   â€¢ It connects to our MySQL backend (deployed in setup)"

wait

echo ""
echo "# ğŸ“‹ Here's the registry instance manifest:"

wait

pe "bat --style=grid,numbers manifests/model-registry-instance.yaml"

wait

pe "oc apply -f manifests/model-registry-instance.yaml"

echo ""
echo "# â³ Waiting for registry to become available..."

wait

pe "oc wait --for=condition=Available mr/fsi-model-registry -n rhoai-model-registries --timeout=120s"

verify_step "Model Registry instance is Available" "oc get mr fsi-model-registry -n rhoai-model-registries -o jsonpath='{.status.conditions[?(@.type==\"Available\")].status}' 2>/dev/null | grep -q True"

echo ""
echo "# âœ… Registry is live! Now register our trained model"

wait

pe "$BROWSER_OPEN \$RHOAI_URL"

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Register model in Model Registry${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# ğŸŒ RHOAI Dashboard â†’ 'Model Registry' in left sidebar"
echo "#   â†’ Select registry: fsi-model-registry"
echo "#   â†’ Click 'Register model'"
echo "#"
echo "# ğŸ“ Model details:"
echo "#   â†’ Model name:        fsi-fraud-detection"
echo "#   â†’ Model description:"
echo "#     Binary classifier for real-time transaction fraud detection."
echo "#     5-feature input (amount, category, time delta, account age,"
echo "#     frequency). Sigmoid output (0-1), >0.5 = suspected fraud."
echo "#"
echo "# ğŸ“¦ Version details:"
echo "#   â†’ Version name:      v1.0"
echo "#   â†’ Version description:"
echo "#     Initial release. Trained on 100K synthetic transactions."
echo "#     Architecture: 5â†’10(ReLU)â†’1(Sigmoid). Validation AUC: 0.94."
echo "#"
echo "# ğŸ”— Model location:"
echo "#   â†’ Source model format:  tensorflow"
echo "#   â†’ Source model version: 2"
echo "#   â†’ Model location (URI): s3://models/production/demo-model/"
echo "#"
echo "#   â†’ Click 'Register model'"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Add custom properties${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# ğŸŒ Click into 'fsi-fraud-detection' â†’ 'v1.0' version"
echo "#   â†’ Look for 'Properties' or 'Custom properties' section"
echo "#   â†’ Add these key-value pairs:"
echo "#"
echo "#   Key                    Value"
echo "#   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
echo "#   team                   FSI Risk Analytics"
echo "#   use_case               Real-time fraud detection"
echo "#   regulatory_framework   PCI-DSS, SOX"
echo "#   data_classification    Confidential - PII Adjacent"
echo "#   owner                  Adam Young"
echo "#   gpu_type               NVIDIA A10G (24GB VRAM)"
echo "#   serving_runtime        NVIDIA Triton 24.01"
echo "#   training_dataset       synthetic_transactions_100k"
echo "#   validation_auc         0.94"
echo "#   risk_tier              Tier 2 - Model risk review complete"
echo "#   approval_status        Approved for staging"
echo "#"
echo "# ğŸ’¡ Why this matters in FSI:"
echo "#   â€¢ Regulators can audit which model version is in production"
echo "#   â€¢ Risk teams see validation metrics + approval status"
echo "#   â€¢ Data governance tracks PII-adjacent classifications"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo "# âœ… Model registered with full metadata"
echo "#   Next: deploy it directly from the registry"

wait
}

section_11() {
begin_section 11 "ğŸš€" "Deploy from Registry & Test Inference" || return 0
# Depends on: Model registered (Section 10), ServingRuntime (Section 7)
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
verify_step "ServingRuntime template exists" "oc get template triton-kserve-gpu-template -n redhat-ods-applications 2>/dev/null"
echo "#"
echo "# ğŸš€ Deploy directly from the Model Registry"
echo "#   â€¢ The registry knows the artifact URI, format, and version"
echo "#   â€¢ Deployment is tracked -- shows up in the registry's Deployments tab"
echo "#   â€¢ Full lineage: trained â†’ registered â†’ deployed â†’ serving"

wait

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Deploy model from registry${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# ğŸŒ RHOAI Dashboard â†’ Model Registry â†’ fsi-model-registry"
echo "#   â†’ Click 'fsi-fraud-detection'"
echo "#   â†’ On version 'v1.0' row â†’ click 'Deploy' (kebab menu or button)"
echo "#"
echo "# ğŸ“ Deployment settings:"
echo "#   â†’ Model name:       fsi-demo-model"
echo "#   â†’ Project:           fsi-demo"
echo "#   â†’ Serving runtime:   Triton Inference Server (GPU)"
echo "#   â†’ Model framework:   tensorflow - 2"
echo "#   â†’ Model location:    should be pre-filled from registry"
echo "#     (if not: Existing connection â†’ minio-models, path: production)"
echo "#   â†’ Advanced settings:"
echo "#     â€¢ External route: UNCHECKED"
echo "#     â€¢ Token auth: UNCHECKED"
echo "#   â†’ Click 'Deploy'"
echo "#   â†’ â³ Wait for status: âœ… green checkmark"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo "# ğŸ”„ Verify deployment from CLI while we wait:"

wait

pe "oc get inferenceservice -n fsi-demo"

# Capture the InferenceService name (Dashboard may auto-generate it from registry)
ISVC_NAME=$(oc get inferenceservice -n fsi-demo -o jsonpath='{.items[0].metadata.name}' 2>/dev/null) || true
echo ""
echo "# â³ Waiting for model to load on GPU..."
echo "#   InferenceService name: ${ISVC_NAME:-unknown}"

verify_step "InferenceService is Ready" "oc get inferenceservice -n fsi-demo -o jsonpath='{.items[0].status.conditions[?(@.type==\"Ready\")].status}' 2>/dev/null | grep -q True"

echo ""
echo "# ğŸ” Check the registry -- Deployments tab should now show this deployment"
echo "#   â†’ Go back to Model Registry â†’ fsi-fraud-detection"
echo "#   â†’ Click 'Deployments' tab"
echo "#   â†’ ${ISVC_NAME:-the deployment} should appear with status"

wait

echo ""
echo "# âœ… Model deployed from registry with full lineage tracking"
echo "#   Now let's send some predictions!"

wait

echo ""
echo "# ğŸ¯ The payoff -- send data to the live model and get a prediction!"
echo "#   â€¢ Our model: 5 floats in â†’ 1 sigmoid probability out"
echo "#   â€¢ Using Triton's v2 REST API from inside the cluster"
echo "#   â€¢ The notebook auto-detects the input tensor name"

wait

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Run inference notebook${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# ğŸŒ In JupyterLab (same workbench from Section 9):"
echo "#   â†’ Navigate to RHOAI-demo/notebooks/"
echo "#   â†’ Open: ğŸ““ inference-test.ipynb"
echo "#"
echo -e "# ${CYAN}âœï¸  FIRST: Update ISVC_NAME in the first code cell:${COLOR_RESET}"
echo "#     ISVC_NAME = \"${ISVC_NAME:-<check oc get inferenceservice>}\""
echo "#"
echo "#   â†’ Then run each cell with Shift+Enter"
echo "#"
echo "# ğŸ’¡ What it does:"
echo "#   1. Queries Triton for model metadata (auto-detects tensor names)"
echo "#   2. Sends two different prediction requests"
echo "#   3. Shows the sigmoid probability output (0-1)"
echo "#"
echo "# ğŸ”‘ In production this would be:"
echo "#   â€¢ Fraud detection scores on transactions"
echo "#   â€¢ Credit risk assessments"
echo "#   â€¢ Real-time pricing models"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo "# âœ… Full custom model lifecycle complete:"
echo "#   Train on GPU â†’ register â†’ deploy from registry â†’ live inference"

wait
}

section_12() {
begin_section 12 "âš™ï¸ " "Data Science Pipelines & Experiments" || return 0
# Depends on: RHOAI installed (Section 4), fsi-demo namespace (Section 9)
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
verify_step "fsi-demo namespace exists" "oc get namespace fsi-demo 2>/dev/null"
echo "#"
echo "# âš™ï¸  Data Science Pipelines = automated, repeatable workflows"
echo "#   â€¢ Kubeflow Pipelines (KFP) on OpenShift"
echo "#   â€¢ Each step = a container with defined inputs/outputs"
echo "#   â€¢ Steps run in sequence or parallel on the cluster"
echo "#   â€¢ Triggered on schedule, git push, or new data"
echo "#"
echo "# ğŸ“‹ A standard ML pipeline looks like:"
echo "#   1ï¸âƒ£  Data Processing   â†’ clean, normalize raw data"
echo "#   2ï¸âƒ£  Feature Extract   â†’ derive model features"
echo "#   3ï¸âƒ£  Train Model       â†’ fit on GPU, output SavedModel"
echo "#   4ï¸âƒ£  Validate          â†’ score against holdout set"
echo "#   5ï¸âƒ£  Upload Model      â†’ push artifacts to S3"
echo "#"
echo "# ğŸ’¡ We did Sections 9-11 manually so you could see each step."
echo "#   In production, the training workflow is a pipeline."
echo "#   Deployment stays separate (Model Registry â†’ Deploy)."

wait

echo ""
echo "# ğŸ”§ Pipeline server was deployed back in Section 9."
echo "#   Let's verify it's ready:"

wait

verify_step "DSPA is Ready" "oc get dspa dspa -n fsi-demo -o jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}' 2>/dev/null | grep -q True"

pe "oc get dspa -n fsi-demo"

wait

echo ""
echo "# ğŸ”§ Step 1: Compile the pipeline"
echo "#   â€¢ Pipeline is written in Python using KFP v2 SDK"
echo "#   â€¢ Each @dsl.component becomes a container step"
echo "#   â€¢ Compiling produces an IR YAML (Intermediate Representation)"
echo "#"
echo "# ğŸ“‹ What is IR YAML?"
echo "#   â€¢ Platform-agnostic pipeline specification"
echo "#   â€¢ Python SDK â†’ compiles â†’ IR YAML â†’ imported into RHOAI"
echo "#   â€¢ The DSPA backend translates IR YAML into an Argo Workflow"
echo "#   â€¢ Same IR works on any KFP v2-compatible backend"
echo "#"
echo "# ğŸ“‹ Our pipeline has 4 steps (we'll add the 5th with Elyra):"
echo "#   data-processing â†’ feature-extract â†’ train-model â†’ upload-model"

wait

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Compile pipeline in workbench${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# ğŸŒ In JupyterLab terminal (same workbench from Section 9):"
echo "#   â†’ Make sure you're in the RHOAI-demo/notebooks/ directory"
echo "#   â†’ Run:"
echo "#"
echo "#     pip install kfp"
echo "#     python fsi-fraud-pipeline.py"
echo "#"
echo "#   â†’ This generates: fsi-fraud-pipeline.yaml (the IR YAML)"
echo "#   â†’ You should see: 'Pipeline compiled to: fsi-fraud-pipeline.yaml'"
echo "#"
echo "#   ğŸ’¡ The Python code defines the pipeline declaratively."
echo "#     The compiler serializes it to IR YAML -- the portable format"
echo "#     that any KFP v2 backend can execute."
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo "# ğŸ”§ Step 2: Import and run the 4-step pipeline"

wait

pe "$BROWSER_OPEN \$RHOAI_URL"

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Import pipeline in RHOAI Dashboard${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# ğŸŒ RHOAI Dashboard â†’ fsi-demo project â†’ 'Pipelines' tab"
echo "#   â†’ Click 'Import pipeline'"
echo "#   â†’ Pipeline name: FSI Fraud Detection Training"
echo "#   â†’ Upload: fsi-fraud-pipeline.yaml (the IR YAML from workbench)"
echo "#     (download from JupyterLab or copy/paste)"
echo "#   â†’ Click 'Import pipeline'"
echo "#"
echo "# ğŸƒ Then create a run:"
echo "#   â†’ Click the pipeline name â†’ 'Create run'"
echo "#   â†’ Run name: fraud-training-run-1"
echo "#   â†’ Experiment: Create new â†’ 'fsi-fraud-experiments'"
echo "#   â†’ Parameters: num_samples = 10000 (default)"
echo "#   â†’ Click 'Create'"
echo "#"
echo "# ğŸ‘€ Watch the pipeline execute:"
echo "#   â†’ Each step lights up as it runs"
echo "#   â†’ Click a step to see its logs"
echo "#   â†’ 4 steps run in sequence:"
echo "#     data-processing â†’ feature-extract â†’ train-model â†’ upload-model"
echo "#"
echo "# ğŸ’¡ Notice: there's no validation step yet!"
echo "#   We'll add that next using the Elyra visual editor."
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo "# ğŸ¨ Step 3: Add Validate step with Elyra"
echo "#   â€¢ Elyra = visual pipeline editor in JupyterLab"
echo "#   â€¢ Drag-and-drop nodes instead of writing Python"
echo "#   â€¢ Each node = a notebook or Python script"
echo "#   â€¢ Two ways to build pipelines:"
echo "#     Code-first: KFP SDK (what we just did)"
echo "#     Visual: Elyra (what we're doing now)"

wait

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Add Validate step in Elyra${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# ğŸŒ In JupyterLab (same workbench):"
echo "#   â†’ File menu â†’ New â†’ Pipeline Editor"
echo "#   â†’ This opens the Elyra visual pipeline canvas"
echo "#"
echo "# ğŸ§© Add the validate step:"
echo "#   â†’ From the file browser, drag validate-model.ipynb"
echo "#     onto the pipeline canvas"
echo "#   â†’ This creates a node for the validation script"
echo "#   â†’ Right-click the node â†’ Properties to configure:"
echo "#     â€¢ Runtime image: pick a Python image"
echo "#     â€¢ Dependencies: numpy, scikit-learn"
echo "#"
echo "# ğŸ’¡ Elyra lets data scientists build pipelines"
echo "#   without writing KFP SDK code. Each node is a"
echo "#   notebook or script -- drag, drop, connect, run."
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo "# ğŸ“Š Step 4: Experiments & Tracking"
echo "#   â€¢ Pipeline runs can be used as experiments"
echo "#   â€¢ The run view tracks those experiments"
echo "#   â€¢ Compare results across runs, reproduce any previous run"

wait

echo ""
echo -e "# ${RED}ğŸ›‘ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Explore Experiments${COLOR_RESET}"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"
echo "#"
echo "# ğŸŒ RHOAI Dashboard â†’ fsi-demo project â†’ 'Experiments' tab"
echo "#   â†’ Click 'fsi-fraud-experiments'"
echo "#   â†’ Shows all runs in this experiment"
echo "#   â†’ Click a completed run to see:"
echo "#     â€¢ DAG visualization (pipeline graph)"
echo "#     â€¢ Per-step logs (training accuracy, AUC score)"
echo "#     â€¢ Input/output artifacts"
echo "#     â€¢ Run parameters and duration"
echo "#"
echo "# ğŸ’¡ In production:"
echo "#   â€¢ Run the pipeline on new data â†’ automatic retraining"
echo "#   â€¢ Compare AUC scores across experiments"
echo "#   â€¢ Promote best model to Model Registry â†’ Deploy"
echo "#   â€¢ Schedule pipelines to run on a cadence"
echo -e "# ${RED}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${COLOR_RESET}"

wait

echo ""
echo "# âœ… Pipeline deployed, run complete, experiment tracked"
echo "#   Manual workflow (Sections 9-11) is now automated"

wait
}

section_13() {
echo ""
echo -e "# ğŸ‰ ${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${COLOR_RESET}"
echo "#"
echo -e "#   ${GREEN}Demo complete!${COLOR_RESET}"
echo "#"
echo "#   What we covered:"
echo "#"
echo "#   ğŸ”§ GPU Infrastructure"
echo "#   â€¢ NFD + NVIDIA GPU Operator on OpenShift"
echo "#   â€¢ Hardware Profiles with GPU tolerations"
echo "#"
echo "#   ğŸŒŸ Foundation Models (GenAI)"
echo "#   â€¢ Model Catalog with pre-validated models"
echo "#   â€¢ One-click Granite LLM deployment via vLLM"
echo "#   â€¢ LlamaStack chat playground"
echo "#"
echo "#   ğŸ§ª Custom ML Models"
echo "#   â€¢ GPU-accelerated training workbenches"
echo "#   â€¢ Model Registry with FSI governance metadata"
echo "#   â€¢ Deploy from registry with full lineage"
echo "#   â€¢ Live inference on A10G GPU"
echo "#"
echo "#   âš™ï¸  Automation"
echo "#   â€¢ Data Science Pipelines (KFP v2 + Elyra)"
echo "#   â€¢ Experiment tracking and reproducibility"
echo "#"
echo -e "#   All on ${CYAN}Red Hat OpenShift AI 3.0${COLOR_RESET} ğŸš€"
echo "#"
echo -e "# ${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${COLOR_RESET}"
}

######################################################################
# Run all sections
######################################################################

section_1
section_2
section_3
section_4
section_5
section_6
section_7
section_8
section_9
section_10
section_11
section_12
section_13
