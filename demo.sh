#!/bin/bash

######################################################################
# RHOAI Demo Script
# Uses demo-magic for stepped command execution with commentary.
# Press ENTER to advance each step. Ctrl+C to exit.
#
# Prerequisites (run setup.sh first):
#   - oc CLI logged into target cluster
#   - NFD Operator installed
#   - NVIDIA GPU Operator installed with ClusterPolicy
#   - GPU machineset provisioned (A10G x2)
#   - MinIO deployed (S3 storage)
#   - MySQL deployed (Model Registry backend)
######################################################################

DEMO_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Preflight: check required tools
MISSING=""
for tool in oc bat helm; do
  if ! command -v "$tool" &>/dev/null; then
    MISSING="$MISSING $tool"
  fi
done
if ! oc whoami &>/dev/null; then
  MISSING="$MISSING oc(not-logged-in)"
fi
if [ -n "$MISSING" ]; then
  echo "ERROR: Missing required tools:$MISSING"
  echo ""
  echo "  oc   ‚Üí brew install openshift-cli (or download from OpenShift console)"
  echo "  bat  ‚Üí brew install bat"
  echo "  helm ‚Üí brew install helm"
  echo "  oc login ‚Üí oc login <cluster-url>"
  exit 1
fi

# Source demo-magic
. "${DEMO_DIR}/demo-magic.sh" -n

# Helper: verify a condition before continuing, retry on failure
# Usage: verify_step "description" "command that returns 0 on success"
verify_step() {
  local desc="$1"
  local cmd="$2"
  while true; do
    if eval "$cmd" &>/dev/null; then
      echo -e "  ${GREEN}‚úÖ ${desc}${COLOR_RESET}"
      return 0
    else
      echo -e "  ${RED}‚ùå ${desc} -- not ready${COLOR_RESET}"
      echo ""
      read -p "  Press ENTER to retry, or 's' to skip: " choice
      if [ "$choice" = "s" ]; then
        echo -e "  ${CYAN}‚è≠Ô∏è  Skipped${COLOR_RESET}"
        return 1
      fi
    fi
  done
}

# Helper: compare live resource against manifest, show diff if mismatched
# Usage: verify_manifest "description" "manifest-file"
verify_manifest() {
  local desc="$1"
  local manifest="$2"
  while true; do
    local diff_output
    diff_output=$(oc diff -f "${DEMO_DIR}/${manifest}" 2>&1)
    local rc=$?
    if [ $rc -eq 0 ]; then
      echo -e "  ${GREEN}‚úÖ ${desc} -- matches manifest${COLOR_RESET}"
      return 0
    elif [ $rc -eq 1 ]; then
      echo -e "  ${CYAN}‚ö†Ô∏è  ${desc} -- differs from manifest:${COLOR_RESET}"
      echo ""
      echo "$diff_output"
      echo ""
      read -p "  (a)pply manifest to fix / (c)ontinue anyway / (r)etry check: " choice
      case "$choice" in
        a) oc apply -f "${DEMO_DIR}/${manifest}" &>/dev/null
           echo -e "  ${GREEN}  Applied.${COLOR_RESET}"
           continue ;;
        c) return 0 ;;
        *) continue ;;
      esac
    else
      echo -e "  ${RED}‚ùå ${desc} -- not found or error${COLOR_RESET}"
      echo ""
      read -p "  Press ENTER to retry, or 's' to skip: " choice
      if [ "$choice" = "s" ]; then
        echo -e "  ${CYAN}‚è≠Ô∏è  Skipped${COLOR_RESET}"
        return 1
      fi
    fi
  done
}

# Helper: section header with optional skip
# Returns 1 if skipped (use: begin_section ... || return 0)
begin_section() {
  local num="$1" icon="$2" title="$3"
  echo ""
  echo -e "# ${icon} ${GREEN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${COLOR_RESET}"
  echo -e "# ${GREEN}SECTION ${num}: ${title}${COLOR_RESET}"
  echo -e "# ${GREEN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${COLOR_RESET}"
  read -p "  Skip this section? (y/N): " SKIP_SECTION
  if [ "$SKIP_SECTION" = "y" ]; then
    echo -e "  ${CYAN}‚è≠Ô∏è  Skipped Section ${num}${COLOR_RESET}"
    return 1
  fi
  return 0
}

# Helper: ensure a variable is set, try to resolve it if not
# Usage: ensure_var RHOAI_URL "oc get gateway ..."
ensure_var() {
  local varname="$1"
  local cmd="$2"
  if [ -z "${!varname:-}" ]; then
    local val
    val=$(eval "$cmd" 2>/dev/null) || true
    if [ -n "$val" ]; then
      eval "$varname=\"$val\""
      echo -e "  ${GREEN}‚úÖ ${varname} resolved${COLOR_RESET}"
    else
      echo -e "  ${RED}‚ö†Ô∏è  Could not resolve ${varname} -- was a previous section skipped?${COLOR_RESET}"
    fi
  fi
}

# Configure
DEMO_PROMPT="${GREEN}‚ûú ${CYAN}\W ${COLOR_RESET}"
TYPE_SPEED=20

# Detect browser-open command (macOS vs Linux)
if command -v open &>/dev/null; then
  BROWSER_OPEN="open"
elif command -v xdg-open &>/dev/null; then
  BROWSER_OPEN="xdg-open"
else
  BROWSER_OPEN="echo"   # fallback: just print the URL
fi

clear

echo ""
echo -e "${GREEN}  ___                 ___ _    _  __ _       _   ___ ${COLOR_RESET}"
echo -e "${GREEN} / _ \ _ __  ___ _ _ / __| |_ (_)/ _| |_    /_\ |_ _|${COLOR_RESET}"
echo -e "${GREEN}| (_) | '_ \/ -_) ' \\\\__ \ ' \| |_|  _|     / _ \ | | ${COLOR_RESET}"
echo -e "${GREEN} \___/| .__/\___|_||_|___/_||_|_|_|  \__| /_/ \_\___|${COLOR_RESET}"
echo -e "${GREEN}      |_|${COLOR_RESET}         ${CYAN}Get Started with OpenShift AI${COLOR_RESET}"
echo ""
echo -e "  ${CYAN}FSI Bootcamp Demo  ‚Ä¢  GPU-Accelerated ML on OpenShift${COLOR_RESET}"
echo ""

wait

######################################################################
# Section functions
######################################################################

section_1() {
begin_section 1 "üîç" "Check Current State" || return 0
echo "#"
echo "# üìã What's already on this cluster (from setup):"
echo "#   ‚Ä¢ NFD Operator -- discovers hardware features"
echo "#   ‚Ä¢ NVIDIA GPU Operator -- manages the GPU stack"

wait

pe "oc get csv -A | grep -E 'nvidia|nfd|rhods'"

echo ""
echo "# üñ•Ô∏è  GPU nodes online?"

wait

pe "oc get nodes -l nvidia.com/gpu.present=true"

pe "oc get nodes -l nvidia.com/gpu.present=true -o custom-columns='NODE:.metadata.name,TAINT:.spec.taints[*].key,EFFECT:.spec.taints[*].effect'"

echo ""
echo "# üö´ These GPU nodes are tainted: nvidia.com/gpu=NoSchedule"
echo "#   ‚Ä¢ Set by the MachineSet -- nodes come up pre-tainted"
echo "#   ‚Ä¢ GPU Operator pods tolerate it (they have to run there)"
echo "#   ‚Ä¢ Everything else is blocked ‚Üí protects expensive GPU nodes"
echo "#   ‚Ä¢ We'll need a HardwareProfile later to let ML workloads in"

wait
}

section_2() {
begin_section 2 "üîé" "Node Feature Discovery (NFD)" || return 0
echo "#"
echo "# üëÅÔ∏è  NFD = the eyes of the cluster"
echo "#   ‚Ä¢ DaemonSet on every node -- scans for hardware"
echo "#   ‚Ä¢ GPUs, FPGAs, SR-IOV -- auto-labeled on the node"
echo "#   ‚Ä¢ GPU Operator reads these labels to deploy drivers"

wait

pe "oc get nodefeaturediscovery -n openshift-nfd"

echo ""
echo "# üè∑Ô∏è  What did NFD find on our GPU nodes?"
echo "#   NFD labels use prefix: feature.node.kubernetes.io/"
echo "#   Key ones:"
echo "#     ‚Ä¢ pci-10de.present=true  ‚Üí 10de = NVIDIA's PCI vendor ID"
echo "#     ‚Ä¢ kernel.version         ‚Üí running kernel"
echo "#     ‚Ä¢ system-os_release.ID   ‚Üí RHCOS / RHEL"

wait

pe "oc describe node \$(oc get nodes -l nvidia.com/gpu.present=true -o jsonpath='{.items[0].metadata.name}') | grep -E 'pci-10de|kernel-version.full|os_release.ID|cpu-model.vendor'"

wait
}

section_3() {
begin_section 3 "üéÆ" "NVIDIA GPU Operator" || return 0
echo "#"
echo "# üîß One operator, entire GPU stack:"
echo "#   ‚Ä¢ Drivers, device plugins, container toolkit, monitoring"
echo "#   ‚Ä¢ All driven by a single CR: ClusterPolicy"

wait

pe "oc get clusterpolicy"

echo ""
echo "# üìã What does the ClusterPolicy configure?"

wait

pe "bat --style=grid,numbers manifests/gpu-cluster-policy.yaml"

echo ""
echo ""
echo "# üè∑Ô∏è  GPU Feature Discovery (GFD) adds nvidia.com/gpu.* labels"
echo "#   ‚Ä¢ Product name, VRAM, CUDA version, driver version"
echo "#   ‚Ä¢ Different from NFD -- GFD queries the GPU directly"

wait

pe "oc get nodes -l nvidia.com/gpu.present=true -o custom-columns='NODE:.metadata.name,GPU:.metadata.labels.nvidia\.com/gpu\.product,VRAM_MB:.metadata.labels.nvidia\.com/gpu\.memory,GPUs:.status.allocatable.nvidia\.com/gpu'"

echo ""
echo "# üöÄ Moment of truth -- nvidia-smi"
echo "#   ‚Ä¢ NVIDIA System Management Interface -- CLI to query the GPU"
echo "#   ‚Ä¢ We're running it FROM INSIDE a driver pod (not the host)"
echo "#   ‚Ä¢ If it returns output, the full stack is working:"
echo "#     drivers compiled ‚Üí device plugin registered ‚Üí toolkit configured"
echo "#"
echo "# üìñ How to read the output:"
echo "#   ‚Ä¢ GPU name + VRAM (A10G, 23028MiB ‚âà 22.5GiB -- marketed as 24GB)"
echo "#   ‚Ä¢ Driver 570.x + CUDA 12.8"
echo "#   ‚Ä¢ Pwr: 24W/300W ‚Üí idle draw / max cap (300W under full load)"
echo "#   ‚Ä¢ P8 = performance state (P0=max, P12=min) -- P8 means idle"
echo "#   ‚Ä¢ Temp 28C ‚Üí cool, expect 60-80C under load"
echo "#   ‚Ä¢ GPU-Util 0%, no processes ‚Üí nothing scheduled yet"

wait

pe "oc exec -n nvidia-gpu-operator \$(oc get pods -n nvidia-gpu-operator --no-headers | grep driver | awk '{print \$1}' | head -n 1) -c nvidia-driver-ctr -- nvidia-smi"

wait
}

section_4() {
begin_section 4 "üì¶" "Install Red Hat OpenShift AI" || return 0
echo "#"
echo "# üß† RHOAI = the ML platform layer on top of OpenShift"
echo "#   ‚Ä¢ Workbenches, model serving, pipelines, model registry"
echo "#   ‚Ä¢ Model Catalog with pre-validated foundation models"
echo "#   ‚Ä¢ LlamaStack for GenAI inference and chat"
echo "#   ‚Ä¢ Install the operator from OperatorHub in the console"

wait

pe "OCP_CONSOLE=\$(oc whoami --show-console) && echo \$OCP_CONSOLE"

pe "$BROWSER_OPEN \$OCP_CONSOLE"

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Install RHOAI in browser${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# üåê OpenShift Console ‚Üí Operators ‚Üí OperatorHub"
echo "#   ‚Üí Search: 'OpenShift AI'"
echo "#   ‚Üí Click 'Red Hat OpenShift AI'"
echo "#   ‚Üí Click 'Install'"
echo "#   ‚Üí Channel: fast | Update approval: Automatic"
echo "#   ‚Üí Accept all other defaults ‚Üí Click 'Install'"
echo "#   ‚Üí ‚è≥ Wait for CSV status: 'Succeeded'"
echo "#"
echo -e "# ${RED}   DO NOT press ENTER until the operator shows 'Succeeded'${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo "# üîÑ Verify the operator installed:"

wait

pe "oc get csv -n redhat-ods-operator | grep rhods"

verify_step "RHOAI operator CSV is Succeeded" "oc get csv -n redhat-ods-operator 2>/dev/null | grep rhods | grep -q Succeeded"

echo ""
echo "# üß© The operator is installed, but it doesn't DO anything yet."
echo "#   We need a DataScienceCluster (DSC) -- the CR that tells"
echo "#   the operator which components to activate."
echo "#"
echo "# üìã DSC components we need:"
echo "#   ‚Ä¢ Dashboard, Workbenches, ModelRegistry ‚Üí Managed (defaults)"
echo "#   ‚Ä¢ KServe ‚Üí Managed (model serving)"
echo "#   ‚Ä¢ DataSciencePipelines ‚Üí Managed (ML pipelines)"
echo "#   ‚Ä¢ LlamaStack ‚Üí Managed (NOT default -- must enable)"
echo "#   ‚Ä¢ ModelMeshServing ‚Üí Removed (deprecated, KServe replaces it)"

wait

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Create DataScienceCluster${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# üåê OpenShift Console ‚Üí Installed Operators ‚Üí Red Hat OpenShift AI"
echo "#   ‚Üí 'DataScienceCluster' tab ‚Üí Click 'Create DataScienceCluster'"
echo "#   ‚Üí Switch to YAML view"
echo "#"
echo "# üìù Find the llamastackoperator section and change it:"
echo "#     llamastackoperator:"
echo "#       managementState: Managed     ‚Üê change from Removed to Managed"
echo "#"
echo "# üí° All other defaults are fine (Dashboard, KServe, Workbenches,"
echo "#   ModelRegistry, Pipelines are already Managed by default)"
echo "#"
echo "#   ‚Üí Click 'Create'"
echo "#   ‚Üí ‚è≥ Wait for status: Phase = Ready (may take 2-3 minutes)"
echo "#"
echo -e "# ${RED}   DO NOT press ENTER until the DSC shows Phase: Ready${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo "# üîÑ Checking RHOAI readiness..."
verify_step "DataScienceCluster exists" "oc get datasciencecluster default-dsc 2>/dev/null"
verify_step "DataScienceCluster phase is Ready" "oc get datasciencecluster default-dsc -o jsonpath='{.status.phase}' 2>/dev/null | grep -q Ready"
verify_step "Dashboard is ready" "oc get datasciencecluster default-dsc -o jsonpath='{.status.conditions[?(@.type==\"DashboardReady\")].status}' 2>/dev/null | grep -q True"
verify_step "KServe is ready" "oc get datasciencecluster default-dsc -o jsonpath='{.status.conditions[?(@.type==\"KserveReady\")].status}' 2>/dev/null | grep -q True"
verify_step "Workbenches ready" "oc get datasciencecluster default-dsc -o jsonpath='{.status.conditions[?(@.type==\"WorkbenchesReady\")].status}' 2>/dev/null | grep -q True"
verify_step "RHOAI Dashboard gateway exists" "oc get gateway data-science-gateway -n openshift-ingress 2>/dev/null"

pe "RHOAI_URL=https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}') && echo \$RHOAI_URL"

echo ""
echo "# üìã What's managed vs removed:"

wait

pe "oc get datasciencecluster -o yaml | grep -A1 managementState"

echo ""
echo "# ‚úÖ RHOAI 3.0 is ready -- all components healthy, LlamaStack enabled"

wait
}

section_5() {
begin_section 5 "üõ°Ô∏è " "Hardware Profile with GPU Toleration" || return 0
# Depends on: RHOAI installed, RHOAI_URL set (Section 4)
verify_step "RHOAI operator is installed" "oc get csv -A 2>/dev/null | grep rhods | grep -q Succeeded"
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
echo "#"
echo "# üîë Remember the GPU taint from Section 1?"
echo "#   ‚Ä¢ HardwareProfile is how RHOAI workloads get past it"
echo "#   ‚Ä¢ Defines: CPU + Memory + GPU requests"
echo "#   ‚Ä¢ Includes toleration so pods CAN schedule on tainted GPU nodes"

wait

echo ""
echo "# üìã Here's what the HardwareProfile looks like:"

wait

pe "bat --style=grid,numbers manifests/hardware-profile.yaml"

echo ""
echo "# üîß Two ways to create this profile:"
echo "#"
echo "#   Option A: Apply the manifest (oc apply)"
echo "#   Option B: Create it manually in the RHOAI Dashboard"
echo "#     ‚Üí Settings ‚Üí Hardware profiles ‚Üí 'Create hardware profile'"
echo "#     ‚Üí Name: nvidia-gpu"
echo "#     ‚Üí Add identifiers: CPU (2 default), Memory (8Gi), nvidia.com/gpu (1)"
echo "#     ‚Üí Add toleration: key=nvidia.com/gpu, effect=NoSchedule, operator=Exists"
echo ""
read -p "  Apply manifest now? (y/n): " HP_CHOICE
if [ "$HP_CHOICE" = "y" ]; then
  pe "oc apply -f manifests/hardware-profile.yaml"
else
  echo ""
  echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
  echo -e "# ${RED}   ACTION REQUIRED -- Create HardwareProfile in RHOAI Dashboard${COLOR_RESET}"
  echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
  echo "#"
  echo "# üåê RHOAI Dashboard ‚Üí Settings ‚Üí Hardware profiles"
  echo "#   ‚Üí Click 'Create hardware profile'"
  echo "#   ‚Üí Name: nvidia-gpu"
  echo "#   ‚Üí Add identifiers:"
  echo "#     ‚Ä¢ CPU:            default=2, min=1, max=8"
  echo "#     ‚Ä¢ Memory:         default=8Gi, min=2Gi, max=32Gi"
  echo "#     ‚Ä¢ nvidia.com/gpu: default=1, min=1, max=2 (type: Accelerator)"
  echo "#   ‚Üí Node scheduling ‚Üí Add toleration:"
  echo "#     ‚Ä¢ Key: nvidia.com/gpu"
  echo "#     ‚Ä¢ Effect: NoSchedule"
  echo "#     ‚Ä¢ Operator: Exists"
  echo "#   ‚Üí Click 'Create'"
  echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
  wait
fi

echo ""
verify_step "HardwareProfile 'nvidia-gpu' exists" "oc get hardwareprofile nvidia-gpu -n redhat-ods-applications 2>/dev/null"
verify_manifest "HardwareProfile config" "manifests/hardware-profile.yaml"

wait

pe "$BROWSER_OPEN \$RHOAI_URL"

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Verify HardwareProfile in browser${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# üåê RHOAI Dashboard ‚Üí Settings ‚Üí Hardware profiles"
echo "#   ‚Üí 'NVIDIA GPU (A10G)' should appear"
echo "#   ‚Üí Click it to verify:"
echo "#     ‚Ä¢ CPU: 2 (1-8)"
echo "#     ‚Ä¢ Memory: 8Gi (2Gi-32Gi)"
echo "#     ‚Ä¢ nvidia.com/gpu: 1 (1-2)"
echo "#     ‚Ä¢ Toleration: nvidia.com/gpu NoSchedule"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait
}

section_6() {
begin_section 6 "üåü" "Model Catalog ‚Äî Deploy Granite LLM" || return 0
# Depends on: RHOAI installed (Section 4), HardwareProfile (Section 5)
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
verify_step "HardwareProfile exists" "oc get hardwareprofile nvidia-gpu -n redhat-ods-applications 2>/dev/null"
echo "#"
echo "# üåü RHOAI includes a Model Catalog of pre-validated models"
echo "#   ‚Ä¢ Red Hat AI Validated: tested, supported, enterprise-ready"
echo "#   ‚Ä¢ Delivered as OCI ModelCar container images"
echo "#   ‚Ä¢ One-click deploy from the Dashboard"
echo "#"
echo "# üì¶ ModelCar = model weights packaged as an OCI container image"
echo "#   ‚Ä¢ Uses the same OCI standard as application containers"
echo "#   ‚Ä¢ Pulled, cached, and distributed by the container runtime"
echo "#   ‚Ä¢ Immutable, version-tagged, stored in any container registry"
echo "#   ‚Ä¢ No S3 or external storage required for deployment"
echo "#   ‚Ä¢ Not just for catalog models -- you can package your own"
echo "#     production models as ModelCar images too"
echo "#"
echo "# üéØ We'll deploy Granite 3.1 8B Instruct (W4A16 quantized)"
echo "#   ‚Ä¢ IBM's enterprise LLM -- instruction-tuned for chat"
echo "#   ‚Ä¢ W4A16 = 4-bit weights, 16-bit activations"
echo "#   ‚Ä¢ Fits easily on our A10G (24GB VRAM)"
echo "#   ‚Ä¢ Served via vLLM -- high-performance LLM inference engine"

wait

pe "$BROWSER_OPEN \$RHOAI_URL"

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Create granite-demo project${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# üåê RHOAI Dashboard ‚Üí 'Data Science Projects' (left sidebar)"
echo "#   ‚Üí Click 'Create data science project'"
echo "#   ‚Üí Name: granite-demo"
echo "#   ‚Üí Click 'Create'"
echo "#"
echo "# üí° A Data Science Project = an OpenShift namespace with RHOAI labels."
echo "#   The deploy dialog can only target existing projects."
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Deploy Granite from Model Catalog${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# üåê RHOAI Dashboard ‚Üí Model Catalog (left sidebar)"
echo "#   ‚Üí Browse the catalog -- show the audience what's available"
echo "#   ‚Üí Find: Granite 3.1 8B Instruct (quantized W4A16)"
echo "#   ‚Üí Click the model card ‚Üí review description, license"
echo "#   ‚Üí Click 'Deploy'"
echo "#"
echo "# üìù Deployment settings:"
echo "#   ‚Üí Model name:       granite-llm"
echo "#   ‚Üí Project:           granite-demo (created above)"
echo "#   ‚Üí Serving runtime:   vLLM NVIDIA GPU ServingRuntime for KServe"
echo "#   ‚Üí Hardware profile:  nvidia-gpu (NVIDIA GPU A10G)"
echo "#   ‚Üí Model location:    should be pre-filled from catalog"
echo "#     oci://registry.redhat.io/rhelai1/modelcar-granite-3-1-8b-instruct-quantized-w4a16:1.5"
echo "#   ‚Üí Advanced settings:"
echo "#     ‚Ä¢ External route: UNCHECKED (internal only)"
echo "#     ‚Ä¢ Token auth: UNCHECKED"
echo "#   ‚Üí Click 'Deploy'"
echo "#"
echo "# ‚è≥ The model image will start pulling. This takes a few minutes"
echo "#   if not pre-warmed. We'll fill the time in the next section!"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo "# üîÑ Verify the deployment started:"

wait

pe "oc get inferenceservice -n granite-demo"

echo ""
echo "# ‚è≥ Model is pulling/loading. Let's talk about serving runtimes"
echo "#   and backing services while we wait..."

wait
}

section_7() {
begin_section 7 "üîß" "Serving Runtimes & Backing Services" || return 0
# Depends on: RHOAI installed (Section 4)
verify_step "RHOAI operator is installed" "oc get csv -A 2>/dev/null | grep rhods | grep -q Succeeded"
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
echo "#"
echo "# üñ•Ô∏è  Serving Runtimes = how models run on GPUs"
echo "#   ‚Ä¢ RHOAI supports multiple runtimes for different use cases"
echo "#   ‚Ä¢ vLLM: high-performance LLM inference (what Granite uses)"
echo "#   ‚Ä¢ Triton: multi-framework ML inference (TF, ONNX, PyTorch)"
echo "#   ‚Ä¢ Each runtime is an OpenShift Template in redhat-ods-applications"
echo "#"
echo "# üì¶ RHOAI 3.0 stores runtimes as OpenShift Templates"
echo "#   ‚Ä¢ Dashboard discovers them in redhat-ods-applications"
echo "#   ‚Ä¢ Template wraps a bare ServingRuntime + metadata:"
echo "#     - API protocol (REST vs gRPC)"
echo "#     - Model type (predictive vs generative AI)"

wait

echo ""
echo "# üîß vLLM is already available (built into RHOAI 3.0)"
echo "#   We used it to deploy Granite in the previous section."
echo "#"
echo "# üìã Now let's add Triton for custom ML models (TensorFlow, etc.)"
echo "#   We'll use this later when we deploy our own trained model."

wait

echo ""
echo "# üìã Here's the Triton ServingRuntime definition:"

wait

pe "bat --style=grid,numbers manifests/serving-runtime.yaml"

echo ""
echo "# üîß Two ways to create this runtime:"
echo "#"
echo "#   Option A: Apply the Template manifest (oc apply)"
echo "#     ‚Üí Applies the pre-wrapped Template directly"
echo "#"
echo "#   Option B: Paste bare YAML in the RHOAI Dashboard"
echo "#     ‚Üí Dashboard asks for protocol + model type, wraps it for you"
echo ""
read -p "  Apply template manifest now? (y/n): " SR_CHOICE
if [ "$SR_CHOICE" = "y" ]; then
  pe "oc apply -f manifests/serving-runtime-template.yaml"
else
  echo ""
  echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
  echo -e "# ${RED}   ACTION REQUIRED -- Create ServingRuntime in RHOAI Dashboard${COLOR_RESET}"
  echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
  echo "#"
  echo "# üìÅ YAML to paste: manifests/serving-runtime.yaml"
  echo "#    (scroll up or open in another terminal)"
  echo "#"
  echo "# üåê RHOAI Dashboard ‚Üí Settings ‚Üí Serving runtimes"
  echo "#   ‚Üí Click 'Add serving runtime'"
  echo "#   ‚Üí API protocol: REST"
  echo "#     (Triton config uses HTTP only -- --allow-grpc=false)"
  echo "#   ‚Üí Model type: Predictive model"
  echo "#     (traditional ML: TensorFlow/Keras/ONNX, not LLM inference)"
  echo "#   ‚Üí Select 'Start from scratch'"
  echo "#   ‚Üí Paste the full YAML from manifests/serving-runtime.yaml"
  echo "#   ‚Üí Click 'Create'"
  echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
  wait
fi

echo ""
verify_step "ServingRuntime template exists" "oc get template triton-kserve-gpu-template -n redhat-ods-applications 2>/dev/null"

echo ""
echo "# ‚úÖ Two serving runtimes available:"
echo "#   ‚Ä¢ vLLM ‚Üí LLMs (Granite, Llama, Mistral)"
echo "#   ‚Ä¢ Triton ‚Üí custom ML (TensorFlow, ONNX, PyTorch)"

wait

echo ""
echo "# üß± Now let's check the backing services (deployed during setup):"
echo "#"
echo "#   üì¶ MinIO ‚Üí S3-compatible object storage"
echo "#     ‚Ä¢ Model files, pipeline artifacts"
echo "#     ‚Ä¢ Production = AWS S3 / Ceph / ODF"
echo "#"
echo "#   üóÑÔ∏è  MySQL ‚Üí Model Registry metadata"
echo "#     ‚Ä¢ Name, version, artifact paths"
echo "#     ‚Ä¢ NOT the models -- just the catalog"

wait

echo ""
echo "# üîÑ Verify they're running:"

wait

pe "oc get pods -l app=minio"

pe "oc get pods -n rhoai-model-registry"

echo ""
verify_step "MinIO pod is Running" "oc get pods -l app=minio -o jsonpath='{.items[0].status.phase}' 2>/dev/null | grep -q Running"
verify_step "Model Registry DB pod is Running" "oc get pods -n rhoai-model-registry -o jsonpath='{.items[0].status.phase}' 2>/dev/null | grep -q Running"

echo ""
echo "# ü™£ Time to create our model storage bucket in MinIO!"
echo "#   ‚Üí This is where our custom trained models will land"

wait

verify_step "MinIO UI route exists" "oc get route minio-ui 2>/dev/null"

pe "MINIO_URL=\$(oc get route minio-ui -o jsonpath='https://{.spec.host}') && echo \$MINIO_URL"

pe "$BROWSER_OPEN \$MINIO_URL"

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Create 'models' bucket in MinIO${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# üåê MinIO Console:"
echo "#   ‚Üí Login:  Username: minio  |  Password: minio123"
echo "#   ‚Üí Sidebar ‚Üí 'Object Browser'"
echo "#   ‚Üí Click 'Create a Bucket'"
echo "#   ‚Üí Bucket name: models"
echo "#   ‚Üí Click 'Create Bucket'"
echo "#   ‚Üí Leave it empty -- notebook will upload here later"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo "# üîÑ Let's check on the Granite deployment while we're here:"

wait

pe "oc get inferenceservice -n granite-demo"

echo ""
echo "# üí° While Granite loads, a look at model storage:"
echo "#   ‚Ä¢ S3 (MinIO, AWS, Ceph) ‚Üí fast iteration during development"
echo "#   ‚Ä¢ OCI ModelCar images ‚Üí immutable, versioned, production-ready"
echo "#   ‚Ä¢ Any model can use either path -- catalog models just ship as ModelCar"

wait
}

section_8() {
begin_section 8 "üí¨" "LlamaStack + Chat with Granite" || return 0
# Depends on: RHOAI installed with LlamaStack (Section 4), Granite deployed (Section 6)
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
echo "#"
echo "# üí¨ LlamaStack = unified API for LLM inference"
echo "#   ‚Ä¢ Open-source project by Meta, supported by Red Hat"
echo "#   ‚Ä¢ Provides a standard API for chat, completions, embeddings"
echo "#   ‚Ä¢ The operator was enabled in the DSC back in Section 4"
echo "#   ‚Ä¢ Now we deploy an INSTANCE pointing at our Granite model"
echo "#   ‚Ä¢ Plus a Playground UI for interactive chat"

wait

echo ""
echo "# üîÑ First, let's make sure Granite is ready:"

wait

pe "oc get inferenceservice -n granite-demo"

verify_step "Granite InferenceService is Ready" "oc get inferenceservice -n granite-demo -o jsonpath='{.items[0].status.conditions[?(@.type==\"Ready\")].status}' 2>/dev/null | grep -q True"

echo ""
echo "# üéØ Granite is serving! Let's set up the chat playground."

wait

# Get the Granite internal endpoint
GRANITE_ISVC=$(oc get inferenceservice -n granite-demo -o jsonpath='{.items[0].metadata.name}' 2>/dev/null) || true
GRANITE_ENDPOINT="http://${GRANITE_ISVC}-predictor.granite-demo.svc.cluster.local:8080/v1"

# Get the model ID that vLLM is serving (needed for LlamaStack config)
GRANITE_MODEL_ID=$(oc exec -n granite-demo deploy/${GRANITE_ISVC}-predictor -c kserve-container -- curl -s http://localhost:8080/v1/models 2>/dev/null | python3 -c "import sys,json; print(json.load(sys.stdin)['data'][0]['id'])" 2>/dev/null) || GRANITE_MODEL_ID="granite"

echo ""
echo "# üîó Granite internal endpoint:"
echo "#   ${GRANITE_ENDPOINT}"
echo "#   Model ID: ${GRANITE_MODEL_ID}"

wait

echo ""
echo "# üîß Step 1: Deploy LlamaStack operator instance"
echo "#   ‚Ä¢ Creates a LlamaStackDistribution CR"
echo "#   ‚Ä¢ The RHOAI-managed operator sees this CR and deploys:"
echo "#     - LlamaStack API server (port 8321)"
echo "#     - ConfigMap with model routing config"
echo "#   ‚Ä¢ Uses a Helm chart from the GenAIOps Helm repo"

wait

echo ""
echo "# üìã Installing LlamaStack operator instance via Helm..."

wait

pe "helm install llama-stack-instance genaiops/llama-stack-operator-instance \
  --namespace granite-demo \
  --set models[0].name=${GRANITE_MODEL_ID} \
  --set models[0].url=${GRANITE_ENDPOINT} \
  --set telemetry.enabled=false \
  --set otelCollector.enabled=false \
  --set rag.enabled=false \
  --set mcp.enabled=false \
  --set mcp_aihub.enabled=false \
  --set eval.enabled=false \
  --set guardrails.enabled=false"

echo ""
echo "# ‚è≥ Waiting for LlamaStack API server to start..."

wait

verify_step "LlamaStack pod is Running" "oc get pods -n granite-demo -l app.kubernetes.io/name=llama-stack -o jsonpath='{.items[0].status.phase}' 2>/dev/null | grep -q Running"

echo ""
echo "# üîß Step 2: Deploy LlamaStack Playground UI"
echo "#   ‚Ä¢ Streamlit-based chat interface"
echo "#   ‚Ä¢ Connects to the LlamaStack API service"
echo "#   ‚Ä¢ Creates an OpenShift Route for browser access"

wait

pe "helm install llama-stack-playground genaiops/llama-stack-playground \
  --namespace granite-demo \
  --set playground.llamaStackUrl=http://llama-stack:8321 \
  --set playground.defaultModel=${GRANITE_MODEL_ID} \
  --set route.enabled=true \
  --set networkPolicy.enabled=false"

echo ""
echo "# ‚è≥ Waiting for Playground to start..."

wait

verify_step "Playground pod is Running" "oc get pods -n granite-demo -l app.kubernetes.io/name=llama-stack-playground -o jsonpath='{.items[0].status.phase}' 2>/dev/null | grep -q Running"

echo ""
echo "# üåê Opening the Playground..."

wait

pe "PLAYGROUND_URL=\$(oc get route -n granite-demo -l app.kubernetes.io/name=llama-stack-playground -o jsonpath='https://{.items[0].spec.host}') && echo \$PLAYGROUND_URL"

pe "$BROWSER_OPEN \$PLAYGROUND_URL"

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Chat with Granite!${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# üåê In the Playground:"
echo "#   ‚Üí Select model: ${GRANITE_MODEL_ID}"
echo "#   ‚Üí Try these FSI-relevant prompts:"
echo "#"
echo "#   üí¨ 'Explain the key components of Basel III capital requirements'"
echo "#   üí¨ 'What are the main risks in algorithmic trading?'"
echo "#   üí¨ 'Summarize PCI-DSS compliance requirements for payment processing'"
echo "#   üí¨ 'What is model risk management and why does it matter in banking?'"
echo "#"
echo "# üîë Key points for the audience:"
echo "#   ‚Ä¢ This model is running on our A10G GPU, on OpenShift"
echo "#   ‚Ä¢ Enterprise-grade: Red Hat validated, IBM-developed"
echo "#   ‚Ä¢ No data leaves the cluster -- internal inference only"
echo "#   ‚Ä¢ From catalog browse to live chat in minutes"
echo "#   ‚Ä¢ LlamaStack provides a standard API -- swap models without"
echo "#     changing your application code"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo "# ‚úÖ Foundation model deployed from catalog and serving live!"
echo "#   Next: build and deploy your OWN custom model"

wait
}

section_9() {
begin_section 9 "üß™" "Workbench & Train Custom Model" || return 0
# Depends on: RHOAI_URL (Section 4), MINIO_URL (Section 7),
#             HardwareProfile (Section 5), ServingRuntime (Section 7)
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
ensure_var MINIO_URL "oc get route minio-ui -o jsonpath='https://{.spec.host}'"
verify_step "HardwareProfile exists" "oc get hardwareprofile nvidia-gpu -n redhat-ods-applications 2>/dev/null"
verify_step "ServingRuntime template exists" "oc get template triton-kserve-gpu-template -n redhat-ods-applications 2>/dev/null"
echo "#"
echo "# üîÄ Shift: from foundation models ‚Üí building your own"
echo "#   ‚Ä¢ Granite gave us GenAI out of the box"
echo "#   ‚Ä¢ But FSI needs custom models too:"
echo "#     fraud detection, credit scoring, risk pricing"
echo "#   ‚Ä¢ Same platform, same GPUs, different workflow"
echo "#"
echo "# üéØ Interactive ML workflow:"
echo "#   1Ô∏è‚É£  Create Data Science Project"
echo "#   2Ô∏è‚É£  Connect S3 storage"
echo "#   3Ô∏è‚É£  Launch GPU workbench"
echo "#   4Ô∏è‚É£  Train model + upload to MinIO"

wait

pe "$BROWSER_OPEN \$RHOAI_URL"

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Create Data Science Project${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# 1Ô∏è‚É£  üåê RHOAI Dashboard:"
echo "#   ‚Üí 'Data Science Projects' in left sidebar"
echo "#   ‚Üí Click 'Create data science project'"
echo "#   ‚Üí Name: fsi-demo"
echo "#   ‚Üí Click 'Create'"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo "# ‚öôÔ∏è  While we're here, let's deploy the pipeline server"
echo "#   so it's ready when we get to Section 12."
echo "#   This takes a couple minutes to start up."

wait

pe "oc apply -f manifests/dspa.yaml"

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Create S3 Connection${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# 2Ô∏è‚É£  Inside fsi-demo project ‚Üí 'Connections' tab"
echo "#   ‚Üí Click 'Create connection'"
echo "#   ‚Üí Connection type: S3 compatible object storage - v1"
echo "#   ‚Üí Connection name:  minio-models"
echo "#   ‚Üí Access key:       minio"
echo "#   ‚Üí Secret key:       minio123"
echo "#   ‚Üí Endpoint:         http://minio-service.default.svc.cluster.local:9000"
echo "#   ‚Üí Bucket:           models"
echo "#   ‚Üí Click 'Create'"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Create GPU Workbench${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# 3Ô∏è‚É£  'Workbenches' tab ‚Üí 'Create workbench'"
echo "#   ‚Üí Name: gpu-workbench"
echo "#   ‚Üí Image: TensorFlow (select CUDA variant if available)"
echo "#   ‚Üí Hardware profile: nvidia-gpu"
echo "#   ‚Üí Connections ‚Üí check 'Attach existing connections'"
echo "#     ‚Üí Select: minio-models"
echo "#   ‚Üí Click 'Create workbench'"
echo "#   ‚Üí ‚è≥ Wait for status: Running"
echo "#   ‚Üí Click 'Open' to launch JupyterLab"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Run notebooks in JupyterLab${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# 4Ô∏è‚É£  In JupyterLab terminal, clone the repo:"
echo "#   ‚Üí git clone https://github.com/adam-d-young/RHOAI-demo.git"
echo "#   ‚Üí Navigate to RHOAI-demo/notebooks/"
echo "#   ‚Üí Run in order:"
echo "#"
echo "#   üìì gpu-check.py        ‚Üí Can TensorFlow see the A10G?"
echo "#   üìì gpu-demo.py         ‚Üí GPU matrix multiply"
echo "#   üìì train-and-upload.py ‚Üí Train model, upload to MinIO"
echo "#"
echo -e "# ${RED}   DO NOT continue until train-and-upload.py completes${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

pe "$BROWSER_OPEN \$MINIO_URL"

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Verify model in MinIO${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# 5Ô∏è‚É£  üåê MinIO Console:"
echo "#   ‚Üí Object Browser ‚Üí 'models' bucket"
echo "#   ‚Üí You should see: production/demo-model/"
echo "#     ‚Üí config.pbtxt"
echo "#     ‚Üí 1/model.savedmodel/saved_model.pb"
echo "#     ‚Üí 1/model.savedmodel/fingerprint.pb"
echo "#     ‚Üí 1/model.savedmodel/variables/"
echo "#"
echo "# ‚úÖ Model trained on GPU, exported, and stored in S3"
echo "#   Next: register it in the Model Registry before deploying"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait
}

section_10() {
begin_section 10 "üìã" "Model Registry" || return 0
# Depends on: RHOAI installed (Section 4), Model trained (Section 9),
#             MySQL DB deployed (setup.sh Step 8)
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
verify_step "RHOAI operator is installed" "oc get csv -A 2>/dev/null | grep rhods | grep -q Succeeded"
verify_step "Model Registry DB is running" "oc get pods -n rhoai-model-registry -o jsonpath='{.items[0].status.phase}' 2>/dev/null | grep -q Running"
echo "#"
echo "# üóÇÔ∏è  Model Registry = the catalog for YOUR models"
echo "#   ‚Ä¢ NOT the Model Catalog (pre-built Red Hat AI models)"
echo "#   ‚Ä¢ Tracks: name, version, description, artifact URI"
echo "#   ‚Ä¢ Add custom properties: team, regulatory, risk tier"
echo "#   ‚Ä¢ Deploy directly from the registry"
echo "#   ‚Ä¢ Full audit trail: who trained it, when, what data"
echo "#"
echo "# üìã In production (FSI), this is critical:"
echo "#   ‚Ä¢ Model Risk Management (SR 11-7 / SS1/23)"
echo "#   ‚Ä¢ Version control for model governance"
echo "#   ‚Ä¢ Deployment tracking across environments"

wait

echo ""
echo "# üîß First, create the Model Registry instance"
echo "#   ‚Ä¢ The RHOAI operator installs the registry capability"
echo "#   ‚Ä¢ But we still need to create an actual registry instance"
echo "#   ‚Ä¢ It connects to our MySQL backend (deployed in setup)"

wait

echo ""
echo "# üìã Here's the registry instance manifest:"

wait

pe "bat --style=grid,numbers manifests/model-registry-instance.yaml"

wait

pe "oc apply -f manifests/model-registry-instance.yaml"

echo ""
echo "# ‚è≥ Waiting for registry to become available..."

wait

pe "oc wait --for=condition=Available mr/fsi-model-registry -n rhoai-model-registries --timeout=120s"

verify_step "Model Registry instance is Available" "oc get mr fsi-model-registry -n rhoai-model-registries -o jsonpath='{.status.conditions[?(@.type==\"Available\")].status}' 2>/dev/null | grep -q True"

echo ""
echo "# ‚úÖ Registry is live! Now register our trained model"

wait

pe "$BROWSER_OPEN \$RHOAI_URL"

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Register model in Model Registry${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# üåê RHOAI Dashboard ‚Üí 'Model Registry' in left sidebar"
echo "#   ‚Üí Select registry: fsi-model-registry"
echo "#   ‚Üí Click 'Register model'"
echo "#"
echo "# üìù Model details:"
echo "#   ‚Üí Model name:        fsi-fraud-detection"
echo "#   ‚Üí Model description:"
echo "#     Binary classifier for real-time transaction fraud detection."
echo "#     5-feature input (amount, category, time delta, account age,"
echo "#     frequency). Sigmoid output (0-1), >0.5 = suspected fraud."
echo "#"
echo "# üì¶ Version details:"
echo "#   ‚Üí Version name:      v1.0"
echo "#   ‚Üí Version description:"
echo "#     Initial release. Trained on 100K synthetic transactions."
echo "#     Architecture: 5‚Üí10(ReLU)‚Üí1(Sigmoid). Validation AUC: 0.94."
echo "#"
echo "# üîó Model location:"
echo "#   ‚Üí Source model format:  tensorflow"
echo "#   ‚Üí Source model version: 2"
echo "#   ‚Üí Model location (URI): s3://models/production/demo-model/"
echo "#"
echo "#   ‚Üí Click 'Register model'"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Add custom properties${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# üåê Click into 'fsi-fraud-detection' ‚Üí 'v1.0' version"
echo "#   ‚Üí Look for 'Properties' or 'Custom properties' section"
echo "#   ‚Üí Add these key-value pairs:"
echo "#"
echo "#   Key                    Value"
echo "#   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
echo "#   team                   FSI Risk Analytics"
echo "#   use_case               Real-time fraud detection"
echo "#   regulatory_framework   PCI-DSS, SOX"
echo "#   data_classification    Confidential - PII Adjacent"
echo "#   owner                  Adam Young"
echo "#   gpu_type               NVIDIA A10G (24GB VRAM)"
echo "#   serving_runtime        NVIDIA Triton 24.01"
echo "#   training_dataset       synthetic_transactions_100k"
echo "#   validation_auc         0.94"
echo "#   risk_tier              Tier 2 - Model risk review complete"
echo "#   approval_status        Approved for staging"
echo "#"
echo "# üí° Why this matters in FSI:"
echo "#   ‚Ä¢ Regulators can audit which model version is in production"
echo "#   ‚Ä¢ Risk teams see validation metrics + approval status"
echo "#   ‚Ä¢ Data governance tracks PII-adjacent classifications"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo "# ‚úÖ Model registered with full metadata"
echo "#   Next: deploy it directly from the registry"

wait
}

section_11() {
begin_section 11 "üöÄ" "Deploy from Registry & Test Inference" || return 0
# Depends on: Model registered (Section 10), ServingRuntime (Section 7)
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
verify_step "ServingRuntime template exists" "oc get template triton-kserve-gpu-template -n redhat-ods-applications 2>/dev/null"
echo "#"
echo "# üöÄ Deploy directly from the Model Registry"
echo "#   ‚Ä¢ The registry knows the artifact URI, format, and version"
echo "#   ‚Ä¢ Deployment is tracked -- shows up in the registry's Deployments tab"
echo "#   ‚Ä¢ Full lineage: trained ‚Üí registered ‚Üí deployed ‚Üí serving"

wait

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Deploy model from registry${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# üåê RHOAI Dashboard ‚Üí Model Registry ‚Üí fsi-model-registry"
echo "#   ‚Üí Click 'fsi-fraud-detection'"
echo "#   ‚Üí On version 'v1.0' row ‚Üí click 'Deploy' (kebab menu or button)"
echo "#"
echo "# üìù Deployment settings:"
echo "#   ‚Üí Model name:       fsi-demo-model"
echo "#   ‚Üí Project:           fsi-demo"
echo "#   ‚Üí Serving runtime:   Triton Inference Server (GPU)"
echo "#   ‚Üí Model framework:   tensorflow - 2"
echo "#   ‚Üí Model location:    should be pre-filled from registry"
echo "#     (if not: Existing connection ‚Üí minio-models, path: production)"
echo "#   ‚Üí Advanced settings:"
echo "#     ‚Ä¢ External route: UNCHECKED"
echo "#     ‚Ä¢ Token auth: UNCHECKED"
echo "#   ‚Üí Click 'Deploy'"
echo "#   ‚Üí ‚è≥ Wait for status: ‚úÖ green checkmark"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo "# üîÑ Verify deployment from CLI while we wait:"

wait

pe "oc get inferenceservice -n fsi-demo"

# Capture the InferenceService name (Dashboard may auto-generate it from registry)
ISVC_NAME=$(oc get inferenceservice -n fsi-demo -o jsonpath='{.items[0].metadata.name}' 2>/dev/null) || true
echo ""
echo "# ‚è≥ Waiting for model to load on GPU..."
echo "#   InferenceService name: ${ISVC_NAME:-unknown}"

verify_step "InferenceService is Ready" "oc get inferenceservice -n fsi-demo -o jsonpath='{.items[0].status.conditions[?(@.type==\"Ready\")].status}' 2>/dev/null | grep -q True"

echo ""
echo "# üîç Check the registry -- Deployments tab should now show this deployment"
echo "#   ‚Üí Go back to Model Registry ‚Üí fsi-fraud-detection"
echo "#   ‚Üí Click 'Deployments' tab"
echo "#   ‚Üí ${ISVC_NAME:-the deployment} should appear with status"

wait

echo ""
echo "# ‚úÖ Model deployed from registry with full lineage tracking"
echo "#   Now let's send some predictions!"

wait

echo ""
echo "# üéØ The payoff -- send data to the live model and get a prediction!"
echo "#   ‚Ä¢ Our model: 5 floats in ‚Üí 1 sigmoid probability out"
echo "#   ‚Ä¢ Using Triton's v2 REST API from inside the cluster"
echo "#   ‚Ä¢ The notebook auto-detects the input tensor name"

wait

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Run inference notebook${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# üåê In JupyterLab (same workbench from Section 9):"
echo "#   ‚Üí Navigate to RHOAI-demo/notebooks/"
echo "#   ‚Üí Open: üìì inference-test.ipynb"
echo "#"
echo -e "# ${CYAN}‚úèÔ∏è  FIRST: Update ISVC_NAME in the first code cell:${COLOR_RESET}"
echo "#     ISVC_NAME = \"${ISVC_NAME:-<check oc get inferenceservice>}\""
echo "#"
echo "#   ‚Üí Then run each cell with Shift+Enter"
echo "#"
echo "# üí° What it does:"
echo "#   1. Queries Triton for model metadata (auto-detects tensor names)"
echo "#   2. Sends two different prediction requests"
echo "#   3. Shows the sigmoid probability output (0-1)"
echo "#"
echo "# üîë In production this would be:"
echo "#   ‚Ä¢ Fraud detection scores on transactions"
echo "#   ‚Ä¢ Credit risk assessments"
echo "#   ‚Ä¢ Real-time pricing models"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo "# ‚úÖ Full custom model lifecycle complete:"
echo "#   Train on GPU ‚Üí register ‚Üí deploy from registry ‚Üí live inference"

wait
}

section_12() {
begin_section 12 "‚öôÔ∏è " "Data Science Pipelines & Experiments" || return 0
# Depends on: RHOAI installed (Section 4), fsi-demo namespace (Section 9)
ensure_var RHOAI_URL "echo https://\$(oc get gateway data-science-gateway -n openshift-ingress -o jsonpath='{.spec.listeners[0].hostname}')"
verify_step "fsi-demo namespace exists" "oc get namespace fsi-demo 2>/dev/null"
echo "#"
echo "# ‚öôÔ∏è  Data Science Pipelines = automated, repeatable workflows"
echo "#   ‚Ä¢ Kubeflow Pipelines (KFP) on OpenShift"
echo "#   ‚Ä¢ Each step = a container with defined inputs/outputs"
echo "#   ‚Ä¢ Steps run in sequence or parallel on the cluster"
echo "#   ‚Ä¢ Triggered on schedule, git push, or new data"
echo "#"
echo "# üìã A standard ML pipeline looks like:"
echo "#   1Ô∏è‚É£  Data Processing   ‚Üí clean, normalize raw data"
echo "#   2Ô∏è‚É£  Feature Extract   ‚Üí derive model features"
echo "#   3Ô∏è‚É£  Train Model       ‚Üí fit on GPU, output SavedModel"
echo "#   4Ô∏è‚É£  Validate          ‚Üí score against holdout set"
echo "#   5Ô∏è‚É£  Upload Model      ‚Üí push artifacts to S3"
echo "#"
echo "# üí° We did Sections 9-11 manually so you could see each step."
echo "#   In production, the training workflow is a pipeline."
echo "#   Deployment stays separate (Model Registry ‚Üí Deploy)."

wait

echo ""
echo "# üîß Pipeline server was deployed back in Section 9."
echo "#   Let's verify it's ready:"

wait

verify_step "DSPA is Ready" "oc get dspa dspa -n fsi-demo -o jsonpath='{.status.conditions[?(@.type==\"Ready\")].status}' 2>/dev/null | grep -q True"

pe "oc get dspa -n fsi-demo"

wait

echo ""
echo "# üîß Step 1: Compile the pipeline"
echo "#   ‚Ä¢ Pipeline is written in Python using KFP v2 SDK"
echo "#   ‚Ä¢ Each @dsl.component becomes a container step"
echo "#   ‚Ä¢ Compiling produces an IR YAML (Intermediate Representation)"
echo "#"
echo "# üìã What is IR YAML?"
echo "#   ‚Ä¢ Platform-agnostic pipeline specification"
echo "#   ‚Ä¢ Python SDK ‚Üí compiles ‚Üí IR YAML ‚Üí imported into RHOAI"
echo "#   ‚Ä¢ The DSPA backend translates IR YAML into an Argo Workflow"
echo "#   ‚Ä¢ Same IR works on any KFP v2-compatible backend"
echo "#"
echo "# üìã Our pipeline has 4 steps (we'll add the 5th with Elyra):"
echo "#   data-processing ‚Üí feature-extract ‚Üí train-model ‚Üí upload-model"

wait

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Compile pipeline in workbench${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# üåê In JupyterLab terminal (same workbench from Section 9):"
echo "#   ‚Üí Make sure you're in the RHOAI-demo/notebooks/ directory"
echo "#   ‚Üí Run:"
echo "#"
echo "#     pip install kfp"
echo "#     python fsi-fraud-pipeline.py"
echo "#"
echo "#   ‚Üí This generates: fsi-fraud-pipeline.yaml (the IR YAML)"
echo "#   ‚Üí You should see: 'Pipeline compiled to: fsi-fraud-pipeline.yaml'"
echo "#"
echo "#   üí° The Python code defines the pipeline declaratively."
echo "#     The compiler serializes it to IR YAML -- the portable format"
echo "#     that any KFP v2 backend can execute."
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo "# üîß Step 2: Import and run the 4-step pipeline"

wait

pe "$BROWSER_OPEN \$RHOAI_URL"

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Import pipeline in RHOAI Dashboard${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# üåê RHOAI Dashboard ‚Üí fsi-demo project ‚Üí 'Pipelines' tab"
echo "#   ‚Üí Click 'Import pipeline'"
echo "#   ‚Üí Pipeline name: FSI Fraud Detection Training"
echo "#   ‚Üí Upload: fsi-fraud-pipeline.yaml (the IR YAML from workbench)"
echo "#     (download from JupyterLab or copy/paste)"
echo "#   ‚Üí Click 'Import pipeline'"
echo "#"
echo "# üèÉ Then create a run:"
echo "#   ‚Üí Click the pipeline name ‚Üí 'Create run'"
echo "#   ‚Üí Run name: fraud-training-run-1"
echo "#   ‚Üí Experiment: Create new ‚Üí 'fsi-fraud-experiments'"
echo "#   ‚Üí Parameters: num_samples = 10000 (default)"
echo "#   ‚Üí Click 'Create'"
echo "#"
echo "# üëÄ Watch the pipeline execute:"
echo "#   ‚Üí Each step lights up as it runs"
echo "#   ‚Üí Click a step to see its logs"
echo "#   ‚Üí 4 steps run in sequence:"
echo "#     data-processing ‚Üí feature-extract ‚Üí train-model ‚Üí upload-model"
echo "#"
echo "# üí° Notice: there's no validation step yet!"
echo "#   We'll add that next using the Elyra visual editor."
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo "# üé® Step 3: Add Validate step with Elyra"
echo "#   ‚Ä¢ Elyra = visual pipeline editor in JupyterLab"
echo "#   ‚Ä¢ Drag-and-drop nodes instead of writing Python"
echo "#   ‚Ä¢ Each node = a notebook or Python script"
echo "#   ‚Ä¢ Two ways to build pipelines:"
echo "#     Code-first: KFP SDK (what we just did)"
echo "#     Visual: Elyra (what we're doing now)"

wait

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Add Validate step in Elyra${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# üåê In JupyterLab (same workbench):"
echo "#   ‚Üí File menu ‚Üí New ‚Üí Pipeline Editor"
echo "#   ‚Üí This opens the Elyra visual pipeline canvas"
echo "#"
echo "# üß© Add the validate step:"
echo "#   ‚Üí From the file browser, drag validate-model.ipynb"
echo "#     onto the pipeline canvas"
echo "#   ‚Üí This creates a node for the validation script"
echo "#   ‚Üí Right-click the node ‚Üí Properties to configure:"
echo "#     ‚Ä¢ Runtime image: pick a Python image"
echo "#     ‚Ä¢ Dependencies: numpy, scikit-learn"
echo "#"
echo "# üí° Elyra lets data scientists build pipelines"
echo "#   without writing KFP SDK code. Each node is a"
echo "#   notebook or script -- drag, drop, connect, run."
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo "# üìä Step 4: Experiments & Tracking"
echo "#   ‚Ä¢ Pipeline runs can be used as experiments"
echo "#   ‚Ä¢ The run view tracks those experiments"
echo "#   ‚Ä¢ Compare results across runs, reproduce any previous run"

wait

echo ""
echo -e "# ${RED}üõë ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo -e "# ${RED}   ACTION REQUIRED -- Explore Experiments${COLOR_RESET}"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"
echo "#"
echo "# üåê RHOAI Dashboard ‚Üí fsi-demo project ‚Üí 'Experiments' tab"
echo "#   ‚Üí Click 'fsi-fraud-experiments'"
echo "#   ‚Üí Shows all runs in this experiment"
echo "#   ‚Üí Click a completed run to see:"
echo "#     ‚Ä¢ DAG visualization (pipeline graph)"
echo "#     ‚Ä¢ Per-step logs (training accuracy, AUC score)"
echo "#     ‚Ä¢ Input/output artifacts"
echo "#     ‚Ä¢ Run parameters and duration"
echo "#"
echo "# üí° In production:"
echo "#   ‚Ä¢ Run the pipeline on new data ‚Üí automatic retraining"
echo "#   ‚Ä¢ Compare AUC scores across experiments"
echo "#   ‚Ä¢ Promote best model to Model Registry ‚Üí Deploy"
echo "#   ‚Ä¢ Schedule pipelines to run on a cadence"
echo -e "# ${RED}‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ${COLOR_RESET}"

wait

echo ""
echo "# ‚úÖ Pipeline deployed, run complete, experiment tracked"
echo "#   Manual workflow (Sections 9-11) is now automated"

wait
}

section_13() {
echo ""
echo -e "# üéâ ${GREEN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${COLOR_RESET}"
echo "#"
echo -e "#   ${GREEN}Demo complete!${COLOR_RESET}"
echo "#"
echo "#   What we covered:"
echo "#"
echo "#   üîß GPU Infrastructure"
echo "#   ‚Ä¢ NFD + NVIDIA GPU Operator on OpenShift"
echo "#   ‚Ä¢ Hardware Profiles with GPU tolerations"
echo "#"
echo "#   üåü Foundation Models (GenAI)"
echo "#   ‚Ä¢ Model Catalog with pre-validated models"
echo "#   ‚Ä¢ One-click Granite LLM deployment via vLLM"
echo "#   ‚Ä¢ LlamaStack chat playground"
echo "#"
echo "#   üß™ Custom ML Models"
echo "#   ‚Ä¢ GPU-accelerated training workbenches"
echo "#   ‚Ä¢ Model Registry with FSI governance metadata"
echo "#   ‚Ä¢ Deploy from registry with full lineage"
echo "#   ‚Ä¢ Live inference on A10G GPU"
echo "#"
echo "#   ‚öôÔ∏è  Automation"
echo "#   ‚Ä¢ Data Science Pipelines (KFP v2 + Elyra)"
echo "#   ‚Ä¢ Experiment tracking and reproducibility"
echo "#"
echo -e "#   All on ${CYAN}Red Hat OpenShift AI 3.0${COLOR_RESET} üöÄ"
echo "#"
echo -e "# ${GREEN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${COLOR_RESET}"
}

######################################################################
# Run all sections
######################################################################

section_1
section_2
section_3
section_4
section_5
section_6
section_7
section_8
section_9
section_10
section_11
section_12
section_13
