# ClusterPolicy - The single CR that drives the entire NVIDIA GPU Operator.
# Every component below is a DaemonSet that runs on GPU nodes.
apiVersion: nvidia.com/v1
kind: ClusterPolicy
metadata:
  name: gpu-cluster-policy
spec:
  operator:
    defaultRuntime: crio            # OpenShift uses CRI-O (not Docker)
    runtimeClass: nvidia

  driver:                           # Kernel modules -- lets the OS talk to the GPU
    enabled: true
    kernelModuleType: auto

  toolkit:                          # Injects GPU device files into containers
    enabled: true
    installDir: /usr/local/nvidia

  devicePlugin:                     # Registers nvidia.com/gpu as a schedulable resource
    enabled: true

  gfd:                              # Labels nodes with GPU product, VRAM, CUDA version
    enabled: true

  dcgm:                             # GPU health monitoring (temp, ECC errors, power)
    enabled: true

  dcgmExporter:                     # Exposes GPU metrics to Prometheus
    enabled: true

  nodeStatusExporter:
    enabled: true

  daemonsets:
    rollingUpdate:
      maxUnavailable: 10%
    tolerations:
      - key: nvidia.com/gpu         # Must tolerate GPU taint to run on GPU nodes
        operator: Exists
    updateStrategy: RollingUpdate

  sandboxWorkloads:
    defaultWorkload: container
    enabled: false
